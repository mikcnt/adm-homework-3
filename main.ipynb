{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T10:41:32.101323Z",
     "iopub.status.busy": "2020-11-26T10:41:32.101131Z",
     "iopub.status.idle": "2020-11-26T10:41:33.274541Z",
     "shell.execute_reply": "2020-11-26T10:41:33.274071Z",
     "shell.execute_reply.started": "2020-11-26T10:41:32.101272Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import string\n",
    "import data_collector\n",
    "import parser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import heapq\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of the books\n",
    "We already have the list of books in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both dirs, bests and links parameters to create the correct directories and download the txt containing all the html links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.588151Z",
     "iopub.status.busy": "2020-11-22T22:28:10.587988Z",
     "iopub.status.idle": "2020-11-22T22:28:10.591041Z",
     "shell.execute_reply": "2020-11-22T22:28:10.590475Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.588099Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(dirs=False, bests=False, links=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Crawl books\n",
    "We already have all the htmls in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both the books and fails parameters to download all the html pages and remove the ones with broken pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.593990Z",
     "iopub.status.busy": "2020-11-22T22:28:10.593855Z",
     "iopub.status.idle": "2020-11-22T22:28:10.634453Z",
     "shell.execute_reply": "2020-11-22T22:28:10.633377Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.593972Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(books=False, fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Parse downloaded pages\n",
    "Set to `True` the create parameter to parse the downloaded html pages and create the tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.635794Z",
     "iopub.status.busy": "2020-11-22T22:28:10.635569Z",
     "iopub.status.idle": "2020-11-22T22:28:10.648884Z",
     "shell.execute_reply": "2020-11-22T22:28:10.648186Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.635759Z"
    }
   },
   "outputs": [],
   "source": [
    "parser.create_tsv(create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T21:14:22.482102Z",
     "iopub.status.busy": "2020-11-25T21:14:22.481789Z",
     "iopub.status.idle": "2020-11-25T21:14:22.790299Z",
     "shell.execute_reply": "2020-11-25T21:14:22.789822Z",
     "shell.execute_reply.started": "2020-11-25T21:14:22.482065Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('parsed_books.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:06:52.624394Z",
     "iopub.status.busy": "2020-11-25T20:06:52.624225Z",
     "iopub.status.idle": "2020-11-25T20:06:52.628135Z",
     "shell.execute_reply": "2020-11-25T20:06:52.627687Z",
     "shell.execute_reply.started": "2020-11-25T20:06:52.624375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29959, 12)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:06:52.629289Z",
     "iopub.status.busy": "2020-11-25T20:06:52.629082Z",
     "iopub.status.idle": "2020-11-25T20:06:52.649296Z",
     "shell.execute_reply": "2020-11-25T20:06:52.648710Z",
     "shell.execute_reply.started": "2020-11-25T20:06:52.629270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen Peeta Mellark Cato (Hunger Ga...</td>\n",
       "      <td>District 12, Panem Capitol, Panem Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>September 2004</td>\n",
       "      <td>Sirius Black Draco Malfoy Ron Weasley Petunia ...</td>\n",
       "      <td>Hogwarts School of Witchcraft and Wizardry Lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>May 23rd 2006</td>\n",
       "      <td>Scout Finch Atticus Finch Jem Finch Arthur Rad...</td>\n",
       "      <td>Maycomb, Alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>October 10th 2000</td>\n",
       "      <td>Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...</td>\n",
       "      <td>United Kingdom Derbyshire, England England Her...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>September 6th 2006</td>\n",
       "      <td>Edward Cullen Jacob Black Laurent Renee Bella ...</td>\n",
       "      <td>Forks, Washington Phoenix, Arizona Washington ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  Suzanne Collins         4.33    6408798.0     172554.0   \n",
       "1     J.K. Rowling         4.50    2525157.0      42734.0   \n",
       "2       Harper Lee         4.28    4527405.0      91802.0   \n",
       "3      Jane Austen         4.26    3017830.0      67811.0   \n",
       "4  Stephenie Meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  Could you survive on your own in the wild, wit...          374.0   \n",
       "1  There is a door at the end of a silent corrido...          870.0   \n",
       "2  The unforgettable novel of a childhood in a sl...          324.0   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...          279.0   \n",
       "4  About three things I was absolutely positive.F...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen Peeta Mellark Cato (Hunger Ga...   \n",
       "1       September 2004  Sirius Black Draco Malfoy Ron Weasley Petunia ...   \n",
       "2        May 23rd 2006  Scout Finch Atticus Finch Jem Finch Arthur Rad...   \n",
       "3    October 10th 2000  Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...   \n",
       "4   September 6th 2006  Edward Cullen Jacob Black Laurent Renee Bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0            District 12, Panem Capitol, Panem Panem   \n",
       "1  Hogwarts School of Witchcraft and Wizardry Lon...   \n",
       "2                                   Maycomb, Alabama   \n",
       "3  United Kingdom Derbyshire, England England Her...   \n",
       "4  Forks, Washington Phoenix, Arizona Washington ...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset cleaning [preliminary steps]\n",
    "Before actually jumping into the work itself, we want our dataframe to be clean, meaning that there are some preliminary steps we need to perform on it. First of all, missing data is something we should pay attention to. Lot's of rows are going to have missing data somewhere, and dealing with missing data it's not that nice. Notice that this will include different strategies for each of the column we will be considering (more details below). Then there is the problem with punctuation, stopwords, stems and so on so forth, so basic text data preprocessing. Let's make a brief recap:\n",
    "\n",
    "1. **Missing data**\n",
    "    - `bookTitle`: if a book is missing the title, then we can safely just remove the instance. In fact, books that are missing the title are actually missing all the informations, meaning that there is a problem with the GoodReads specific link. Also, even if a book was missing just the title, we wouldn't have a way to refer to it, thus it wouldn't be really useful considering we're building a search engine.\n",
    "    - `bookSeries`, `Authors`, `Plot`, `PublishingDate`, `Characters`, `Setting`: if a book is missing one of the above mentioned columns, we can still include the book in the data, since the search engine could for example work with just the title. Obviously, we cannot just leave the values missing, since it would be really hard to perform any operation on that. These are all text columns, therefore the best way to address the missing values prolem is to replace NaNs with empty strings.\n",
    "    - `ratingValue`, `NumberofPages`: TODO?\n",
    "2. **Text data preprocessing**\n",
    "    - Punctuation removal: this is the first step we want to perform, since it is going to make the next steps much easier (e.g., language detection will be easier if there aren't plots composed just by punctuation symbols).\n",
    "    - Language detection: before doing anything else, we want to remove the books that present the books for which the plot isn't in english.\n",
    "    - Stopwords removal (of the `Plot` column only)\n",
    "    - Stemming (of the `Plot` column only)\n",
    "    - Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title\n",
    "There are 774 books that are completely empty, and these corresponds to the ones that are missing the `bookTitle` column. If you give a look at the url, you can see that these are not given by our python script to download and parse the books, but actually from the fact that the link is broken. Also, you can see that all the books that are missing the `bookTitle` are also missing all the remaining data.\n",
    "\n",
    "This means that we can safely just remove all the rows that are missing the `bookTitle` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:31.908925Z",
     "iopub.status.busy": "2020-11-25T20:39:31.908682Z",
     "iopub.status.idle": "2020-11-25T20:39:31.932318Z",
     "shell.execute_reply": "2020-11-25T20:39:31.931804Z",
     "shell.execute_reply.started": "2020-11-25T20:39:31.908897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 774 instances that are missing the `bookTitle` column.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40937505\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528535\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528544\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40941582\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/5295735\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bookTitle bookSeries bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "311        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "370        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "379        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "789        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "1141       NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Plot  numberOfPages PublishingDate Characters Setting  \\\n",
       "311   NaN            NaN            NaN        NaN     NaN   \n",
       "370   NaN            NaN            NaN        NaN     NaN   \n",
       "379   NaN            NaN            NaN        NaN     NaN   \n",
       "789   NaN            NaN            NaN        NaN     NaN   \n",
       "1141  NaN            NaN            NaN        NaN     NaN   \n",
       "\n",
       "                                                   Url  \n",
       "311   https://www.goodreads.com/book/show/40937505\\r\\n  \n",
       "370   https://www.goodreads.com/book/show/30528535\\r\\n  \n",
       "379   https://www.goodreads.com/book/show/30528544\\r\\n  \n",
       "789   https://www.goodreads.com/book/show/40941582\\r\\n  \n",
       "1141   https://www.goodreads.com/book/show/5295735\\r\\n  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing = df[(df['bookTitle'].isna())].shape[0]\n",
    "print('There are {} instances that are missing the `bookTitle` column.'.format(n_missing))\n",
    "print()\n",
    "df[(df['bookTitle'].isna())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:32.072804Z",
     "iopub.status.busy": "2020-11-25T20:39:32.072642Z",
     "iopub.status.idle": "2020-11-25T20:39:32.081468Z",
     "shell.execute_reply": "2020-11-25T20:39:32.080946Z",
     "shell.execute_reply.started": "2020-11-25T20:39:32.072786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove empty books\n",
    "df = df[(df['bookTitle'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:33.717347Z",
     "iopub.status.busy": "2020-11-25T20:39:33.716718Z",
     "iopub.status.idle": "2020-11-25T20:39:33.735160Z",
     "shell.execute_reply": "2020-11-25T20:39:33.734668Z",
     "shell.execute_reply.started": "2020-11-25T20:39:33.717269Z"
    }
   },
   "outputs": [],
   "source": [
    "str_columns = ['bookSeries', 'bookAuthors', 'Plot', 'PublishingDate', 'Characters', 'Setting']\n",
    "\n",
    "for col in str_columns:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "There are several ways to remove punctuations, including the use of exernal libraries (like nltk). But actually the fastest way to perform punctuation removal is the use of the internal methong translate, which is programmed in C and therefore it's much faster than the other options (give a look to this [link](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string) for a nice performance analysis of the various options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:41:20.710810Z",
     "iopub.status.busy": "2020-11-25T20:41:20.710147Z",
     "iopub.status.idle": "2020-11-25T20:41:20.716628Z",
     "shell.execute_reply": "2020-11-25T20:41:20.715966Z",
     "shell.execute_reply.started": "2020-11-25T20:41:20.710728Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation + '’—'))\n",
    "\n",
    "def remove_punctuation_(s):\n",
    "    return re.sub(\"[^\\w\\s]\", \" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:07:41.092774Z",
     "iopub.status.busy": "2020-11-25T20:07:41.092547Z",
     "iopub.status.idle": "2020-11-25T20:07:41.844175Z",
     "shell.execute_reply": "2020-11-25T20:07:41.843679Z",
     "shell.execute_reply.started": "2020-11-25T20:07:41.092746Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    if col == 'Plot':\n",
    "        df[col] = df[col].apply(remove_punctuation_)\n",
    "    else:\n",
    "        df[col] = df[col].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:11:07.055797Z",
     "iopub.status.busy": "2020-11-22T13:11:07.055640Z",
     "iopub.status.idle": "2020-11-22T13:11:07.074512Z",
     "shell.execute_reply": "2020-11-22T13:11:07.073991Z",
     "shell.execute_reply.started": "2020-11-22T13:11:07.055779Z"
    }
   },
   "source": [
    "#### Language detection\n",
    "There are four possibilities `Plot` column of a given book:\n",
    "1. It is written in english\n",
    "2. It is written in another language\n",
    "3. It is empty\n",
    "4. It contains symbols, numbers, and so on\n",
    "\n",
    "We want to keep only the ones written in english or empty, so we are just going to discard the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:07:46.940690Z",
     "iopub.status.busy": "2020-11-25T20:07:46.940514Z",
     "iopub.status.idle": "2020-11-25T20:07:46.943455Z",
     "shell.execute_reply": "2020-11-25T20:07:46.942954Z",
     "shell.execute_reply.started": "2020-11-25T20:07:46.940671Z"
    }
   },
   "outputs": [],
   "source": [
    "def language(s):\n",
    "    if s == '':\n",
    "        return 'empty'\n",
    "    try:\n",
    "        return detect(s)\n",
    "    except:\n",
    "        return 'symbols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:07:47.025425Z",
     "iopub.status.busy": "2020-11-25T20:07:47.025241Z",
     "iopub.status.idle": "2020-11-25T20:09:53.400501Z",
     "shell.execute_reply": "2020-11-25T20:09:53.400043Z",
     "shell.execute_reply.started": "2020-11-25T20:07:47.025405Z"
    }
   },
   "outputs": [],
   "source": [
    "df['plot_lang'] = df['Plot'].apply(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.401361Z",
     "iopub.status.busy": "2020-11-25T20:09:53.401215Z",
     "iopub.status.idle": "2020-11-25T20:09:53.420128Z",
     "shell.execute_reply": "2020-11-25T20:09:53.419712Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.401343Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['plot_lang'] == 'en'].drop(columns=['plot_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.421196Z",
     "iopub.status.busy": "2020-11-25T20:09:53.421061Z",
     "iopub.status.idle": "2020-11-25T20:09:53.446046Z",
     "shell.execute_reply": "2020-11-25T20:09:53.445548Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.421178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26126, 12)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords removal\n",
    "We are not going to perform stopwords removal on all the columns, since we could remove important things (e.g., we don't want to remove anything from the names of the characters). The only column on which stopwords removal is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.447014Z",
     "iopub.status.busy": "2020-11-25T20:09:53.446856Z",
     "iopub.status.idle": "2020-11-25T20:09:53.454281Z",
     "shell.execute_reply": "2020-11-25T20:09:53.453818Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.446996Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(s):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.455059Z",
     "iopub.status.busy": "2020-11-25T20:09:53.454924Z",
     "iopub.status.idle": "2020-11-25T20:10:10.937813Z",
     "shell.execute_reply": "2020-11-25T20:10:10.937380Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.455040Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "As for the stopwords removal, the only column on which stemming is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:10:10.938712Z",
     "iopub.status.busy": "2020-11-25T20:10:10.938585Z",
     "iopub.status.idle": "2020-11-25T20:10:10.944140Z",
     "shell.execute_reply": "2020-11-25T20:10:10.943681Z",
     "shell.execute_reply.started": "2020-11-25T20:10:10.938695Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemming(s):\n",
    "    ps = PorterStemmer()\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([ps.stem(w) for w in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:10:10.944945Z",
     "iopub.status.busy": "2020-11-25T20:10:10.944812Z",
     "iopub.status.idle": "2020-11-25T20:11:44.967705Z",
     "shell.execute_reply": "2020-11-25T20:11:44.967208Z",
     "shell.execute_reply.started": "2020-11-25T20:10:10.944927Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(stemming)\n",
    "df['Plot'] = df['Plot'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:16:37.617866Z",
     "iopub.status.busy": "2020-11-22T15:16:37.617156Z",
     "iopub.status.idle": "2020-11-22T15:17:23.722941Z",
     "shell.execute_reply": "2020-11-22T15:17:23.722477Z",
     "shell.execute_reply.started": "2020-11-22T15:16:37.617782Z"
    }
   },
   "source": [
    "#### Lowercase\n",
    "On the other hand, we want all the string columns to be lowercase, so that our search engine won't have problems with upper/lower case differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:44.968852Z",
     "iopub.status.busy": "2020-11-25T20:11:44.968725Z",
     "iopub.status.idle": "2020-11-25T20:11:45.017540Z",
     "shell.execute_reply": "2020-11-25T20:11:45.017057Z",
     "shell.execute_reply.started": "2020-11-25T20:11:44.968835Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(lambda w: w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:45.018349Z",
     "iopub.status.busy": "2020-11-25T20:11:45.018215Z",
     "iopub.status.idle": "2020-11-25T20:11:45.043678Z",
     "shell.execute_reply": "2020-11-25T20:11:45.042964Z",
     "shell.execute_reply.started": "2020-11-25T20:11:45.018331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>the hunger games 1</td>\n",
       "      <td>suzanne collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>september 14th 2008</td>\n",
       "      <td>katniss everdeen peeta mellark cato hunger gam...</td>\n",
       "      <td>district 12 panem capitol panem panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>harry potter 5</td>\n",
       "      <td>jk rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>there door end silent corridor and haunt harri...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>september 2004</td>\n",
       "      <td>sirius black draco malfoy ron weasley petunia ...</td>\n",
       "      <td>hogwarts school of witchcraft and wizardry lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>the unforgett novel childhood sleepi southern ...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>may 23rd 2006</td>\n",
       "      <td>scout finch atticus finch jem finch arthur rad...</td>\n",
       "      <td>maycomb alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td></td>\n",
       "      <td>jane austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>altern cover edit isbn 9780679783268sinc immed...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>october 10th 2000</td>\n",
       "      <td>mr bennet mrs bennet jane bennet elizabeth ben...</td>\n",
       "      <td>united kingdom derbyshire england england hert...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>the twilight saga 1</td>\n",
       "      <td>stephenie meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>about three thing i absolut posit first edward...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>september 6th 2006</td>\n",
       "      <td>edward cullen jacob black laurent renee bella ...</td>\n",
       "      <td>forks washington phoenix arizona washington state</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games     the hunger games 1   \n",
       "1  Harry Potter and the Order of the Phoenix         harry potter 5   \n",
       "2                      To Kill a Mockingbird  to kill a mockingbird   \n",
       "3                        Pride and Prejudice                          \n",
       "4                                   Twilight    the twilight saga 1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  suzanne collins         4.33    6408798.0     172554.0   \n",
       "1       jk rowling         4.50    2525157.0      42734.0   \n",
       "2       harper lee         4.28    4527405.0      91802.0   \n",
       "3      jane austen         4.26    3017830.0      67811.0   \n",
       "4  stephenie meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  could surviv wild everi one make sure live see...          374.0   \n",
       "1  there door end silent corridor and haunt harri...          870.0   \n",
       "2  the unforgett novel childhood sleepi southern ...          324.0   \n",
       "3  altern cover edit isbn 9780679783268sinc immed...          279.0   \n",
       "4  about three thing i absolut posit first edward...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  september 14th 2008  katniss everdeen peeta mellark cato hunger gam...   \n",
       "1       september 2004  sirius black draco malfoy ron weasley petunia ...   \n",
       "2        may 23rd 2006  scout finch atticus finch jem finch arthur rad...   \n",
       "3    october 10th 2000  mr bennet mrs bennet jane bennet elizabeth ben...   \n",
       "4   september 6th 2006  edward cullen jacob black laurent renee bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0              district 12 panem capitol panem panem   \n",
       "1  hogwarts school of witchcraft and wizardry lon...   \n",
       "2                                    maycomb alabama   \n",
       "3  united kingdom derbyshire england england hert...   \n",
       "4  forks washington phoenix arizona washington state   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:45.045056Z",
     "iopub.status.busy": "2020-11-25T20:11:45.044805Z",
     "iopub.status.idle": "2020-11-25T20:11:45.058014Z",
     "shell.execute_reply": "2020-11-25T20:11:45.057449Z",
     "shell.execute_reply.started": "2020-11-25T20:11:45.045024Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:45.058683Z",
     "iopub.status.busy": "2020-11-25T20:11:45.058557Z",
     "iopub.status.idle": "2020-11-25T20:11:45.579037Z",
     "shell.execute_reply": "2020-11-25T20:11:45.578498Z",
     "shell.execute_reply.started": "2020-11-25T20:11:45.058666Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T14:46:43.146915Z",
     "iopub.status.busy": "2020-11-26T14:46:43.146701Z",
     "iopub.status.idle": "2020-11-26T14:46:43.365512Z",
     "shell.execute_reply": "2020-11-26T14:46:43.365092Z",
     "shell.execute_reply.started": "2020-11-26T14:46:43.146889Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T10:41:42.321100Z",
     "iopub.status.busy": "2020-11-26T10:41:42.320743Z",
     "iopub.status.idle": "2020-11-26T10:41:42.327187Z",
     "shell.execute_reply": "2020-11-26T10:41:42.326151Z",
     "shell.execute_reply.started": "2020-11-26T10:41:42.321056Z"
    }
   },
   "outputs": [],
   "source": [
    "# To save and load python dictionaries\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T10:41:42.532689Z",
     "iopub.status.busy": "2020-11-26T10:41:42.532420Z",
     "iopub.status.idle": "2020-11-26T10:41:42.536652Z",
     "shell.execute_reply": "2020-11-26T10:41:42.536089Z",
     "shell.execute_reply.started": "2020-11-26T10:41:42.532657Z"
    }
   },
   "outputs": [],
   "source": [
    "def term_index(documents):\n",
    "    words = set()\n",
    "    for s in documents:\n",
    "        try:\n",
    "            tokens = set(word_tokenize(s))\n",
    "            words.update(tokens)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    term_index = {}\n",
    "    for i, word in enumerate(words):\n",
    "        term_index[word] = i\n",
    "    return term_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:24.832442Z",
     "iopub.status.busy": "2020-11-25T20:42:24.831795Z",
     "iopub.status.idle": "2020-11-25T20:42:33.100048Z",
     "shell.execute_reply": "2020-11-25T20:42:33.099569Z",
     "shell.execute_reply.started": "2020-11-25T20:42:24.832362Z"
    }
   },
   "outputs": [],
   "source": [
    "term_indexes = term_index(df['Plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T21:34:23.746839Z",
     "iopub.status.busy": "2020-11-25T21:34:23.746059Z",
     "iopub.status.idle": "2020-11-25T21:34:23.772752Z",
     "shell.execute_reply": "2020-11-25T21:34:23.772094Z",
     "shell.execute_reply.started": "2020-11-25T21:34:23.746740Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(term_indexes, 'vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T10:41:46.813823Z",
     "iopub.status.busy": "2020-11-26T10:41:46.813510Z",
     "iopub.status.idle": "2020-11-26T10:41:46.817126Z",
     "shell.execute_reply": "2020-11-26T10:41:46.816609Z",
     "shell.execute_reply.started": "2020-11-26T10:41:46.813783Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverted_index(documents, term_indexes):\n",
    "    inv_index = defaultdict(list)\n",
    "    for i, s in enumerate(documents):\n",
    "        try:\n",
    "            tokens = set(word_tokenize(s))\n",
    "            for token in tokens:\n",
    "                token_index = term_indexes[token]\n",
    "                inv_index[token_index].append(i)\n",
    "        except:\n",
    "            continue\n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:35.468466Z",
     "iopub.status.busy": "2020-11-25T20:42:35.468107Z",
     "iopub.status.idle": "2020-11-25T20:42:45.479227Z",
     "shell.execute_reply": "2020-11-25T20:42:45.477769Z",
     "shell.execute_reply.started": "2020-11-25T20:42:35.468423Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_indexes = inverted_index(df['Plot'], term_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:45.481584Z",
     "iopub.status.busy": "2020-11-25T20:42:45.481072Z",
     "iopub.status.idle": "2020-11-25T20:42:45.571401Z",
     "shell.execute_reply": "2020-11-25T20:42:45.570771Z",
     "shell.execute_reply.started": "2020-11-25T20:42:45.481475Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(inv_indexes, 'inverted_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T14:46:56.791586Z",
     "iopub.status.busy": "2020-11-26T14:46:56.791342Z",
     "iopub.status.idle": "2020-11-26T14:46:57.594993Z",
     "shell.execute_reply": "2020-11-26T14:46:57.594434Z",
     "shell.execute_reply.started": "2020-11-26T14:46:56.791557Z"
    }
   },
   "outputs": [],
   "source": [
    "term_indexes = load_obj('vocabulary')\n",
    "inv_indexes = load_obj('inverted_index')\n",
    "tfidf_indexes = load_obj('tfidf_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:09:09.347321Z",
     "iopub.status.busy": "2020-11-26T15:09:09.347142Z",
     "iopub.status.idle": "2020-11-26T15:09:09.352494Z",
     "shell.execute_reply": "2020-11-26T15:09:09.352041Z",
     "shell.execute_reply.started": "2020-11-26T15:09:09.347301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write it as a classs\n",
    "\n",
    "class SimpleSearchEngine:\n",
    "    def __init__(self, df, term_indexes, inv_indexes):\n",
    "        self.df = df\n",
    "        self.term_indexes = term_indexes\n",
    "        self.inv_indexes = inv_indexes\n",
    "        \n",
    "    def search(self, query):\n",
    "        # Since we performed stemming on the plot column of the dataframe, we need to\n",
    "        # perform stemming also on the query. Otherwise, our results wouldn't be accurate\n",
    "        ps = PorterStemmer()\n",
    "        query_tokens = set([ps.stem(w) for w in word_tokenize(query)])\n",
    "\n",
    "        # Create term indexes for the query\n",
    "        # notice: if one of the query element doesn't appear in the term_indexes dictionary\n",
    "        # we can safely say that the **conjunctive** query has to return nothing\n",
    "        term_indexes_tokens = []\n",
    "        for token in query_tokens:\n",
    "            if token in self.term_indexes.keys():\n",
    "                term_indexes_tokens.append(self.term_indexes[token])\n",
    "            else:\n",
    "                return pd.DataFrame(columns=['bookTitle', 'Plot', 'Url'])\n",
    "\n",
    "        query_inv_indexes = {}\n",
    "        for token_index in term_indexes_tokens:\n",
    "            query_inv_indexes[token_index] = set(self.inv_indexes[token_index])\n",
    "\n",
    "        # Since it is a conjuntive query, we need to intersect the results of each query token\n",
    "        documents_id = sorted(set.intersection(*query_inv_indexes.values()))\n",
    "\n",
    "        return pd.DataFrame(data=self.df[self.df['index'].isin(documents_id)])\n",
    "    \n",
    "    def execute_query(self, query):\n",
    "        return self.search(query)[['bookTitle', 'Plot', 'Url']]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:09:09.461408Z",
     "iopub.status.busy": "2020-11-26T15:09:09.461231Z",
     "iopub.status.idle": "2020-11-26T15:09:09.464118Z",
     "shell.execute_reply": "2020-11-26T15:09:09.463641Z",
     "shell.execute_reply.started": "2020-11-26T15:09:09.461389Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_SE = SimpleSearchEngine(df, term_indexes, inv_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:09:10.013421Z",
     "iopub.status.busy": "2020-11-26T15:09:10.012997Z",
     "iopub.status.idle": "2020-11-26T15:09:10.029200Z",
     "shell.execute_reply": "2020-11-26T15:09:10.028641Z",
     "shell.execute_reply.started": "2020-11-26T15:09:10.013369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>spark are ignit flame are spread and the capit...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6148028-ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Legend</td>\n",
       "      <td>what western unit state home republ nation per...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9275658-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>The Magus</td>\n",
       "      <td>thi dare literari thriller rich erot suspen on...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16286.The_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25067</th>\n",
       "      <td>The Manhattan Hunt Club</td>\n",
       "      <td>in manhattan hunt club john saul plumb depth m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6553.The_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25531</th>\n",
       "      <td>Love's Forbidden Flower</td>\n",
       "      <td>plea note thi new adult romanc novel involv tw...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16189423-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25806</th>\n",
       "      <td>The Southpaw</td>\n",
       "      <td>the southpaw stori come age america way baseb ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/413736.The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25827</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26064</th>\n",
       "      <td>Indian Hill</td>\n",
       "      <td>a michael talbot adventur thi first stori ordi...</td>\n",
       "      <td>https://www.goodreads.com/book/show/13305176-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bookTitle  \\\n",
       "0             The Hunger Games   \n",
       "221              Catching Fire   \n",
       "319                 Mockingjay   \n",
       "337                     Legend   \n",
       "652                  The Magus   \n",
       "...                        ...   \n",
       "25067  The Manhattan Hunt Club   \n",
       "25531  Love's Forbidden Flower   \n",
       "25806             The Southpaw   \n",
       "25827              Devil's Own   \n",
       "26064              Indian Hill   \n",
       "\n",
       "                                                    Plot  \\\n",
       "0      could surviv wild everi one make sure live see...   \n",
       "221    spark are ignit flame are spread and the capit...   \n",
       "319    the final book ground break hunger game trilog...   \n",
       "337    what western unit state home republ nation per...   \n",
       "652    thi dare literari thriller rich erot suspen on...   \n",
       "...                                                  ...   \n",
       "25067  in manhattan hunt club john saul plumb depth m...   \n",
       "25531  plea note thi new adult romanc novel involv tw...   \n",
       "25806  the southpaw stori come age america way baseb ...   \n",
       "25827  after surviv slaveri aiden macalpin noth thoug...   \n",
       "26064  a michael talbot adventur thi first stori ordi...   \n",
       "\n",
       "                                                     Url  \n",
       "0      https://www.goodreads.com/book/show/2767052-th...  \n",
       "221    https://www.goodreads.com/book/show/6148028-ca...  \n",
       "319    https://www.goodreads.com/book/show/7260188-mo...  \n",
       "337    https://www.goodreads.com/book/show/9275658-le...  \n",
       "652    https://www.goodreads.com/book/show/16286.The_...  \n",
       "...                                                  ...  \n",
       "25067  https://www.goodreads.com/book/show/6553.The_M...  \n",
       "25531  https://www.goodreads.com/book/show/16189423-l...  \n",
       "25806  https://www.goodreads.com/book/show/413736.The...  \n",
       "25827  https://www.goodreads.com/book/show/8705483-de...  \n",
       "26064  https://www.goodreads.com/book/show/13305176-i...  \n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_SE.execute_query('survival games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:09:20.488570Z",
     "iopub.status.busy": "2020-11-26T15:09:20.488409Z",
     "iopub.status.idle": "2020-11-26T15:09:20.493388Z",
     "shell.execute_reply": "2020-11-26T15:09:20.492704Z",
     "shell.execute_reply.started": "2020-11-26T15:09:20.488552Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_inv_indexes(documents, term_indexes, inv_indexes, corpus=df):\n",
    "    tfidf_indexes = defaultdict(dict)\n",
    "    for doc_id, s in enumerate(documents):\n",
    "        try:\n",
    "            tokens = word_tokenize(s)\n",
    "            tokens_set = set(tokens)\n",
    "            n_tokens = len(tokens)\n",
    "            norm = 0\n",
    "            for token in tokens_set:\n",
    "                token_index = term_indexes[token]\n",
    "                # tf = n_times token appears in the document over the number of words of the document\n",
    "                tf = s.count(token) / n_tokens\n",
    "                # idf = log of the number of documents in the corpus over the number of documents in which the token appears\n",
    "                idf = math.log10(len(corpus) / (len(inv_indexes[token_index])))\n",
    "                tf_idf = tf * idf\n",
    "                # we just computed the tfidf for the a particular token, for the document we're considering\n",
    "                tfidf_indexes[token_index][doc_id] = tf * idf\n",
    "                \n",
    "                # Store also the norm for the document we're considering\n",
    "                # which is sqrt of the sum of the squares\n",
    "                norm += tf_idf ** 2\n",
    "                \n",
    "            # apply sqrt\n",
    "            norm = np.sqrt(norm)\n",
    "            # Normalize each document tfidf\n",
    "            for token in tokens_set:\n",
    "                token_index = term_indexes[token]\n",
    "                tfidf_indexes[token_index][doc_id] /= norm\n",
    "        except:\n",
    "            continue\n",
    "    return tfidf_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T14:47:00.956512Z",
     "iopub.status.busy": "2020-11-26T14:47:00.956345Z",
     "iopub.status.idle": "2020-11-26T14:47:16.847091Z",
     "shell.execute_reply": "2020-11-26T14:47:16.846563Z",
     "shell.execute_reply.started": "2020-11-26T14:47:00.956494Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_indexes = tfidf_inv_indexes(df['Plot'], term_indexes, inv_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T14:47:16.847871Z",
     "iopub.status.busy": "2020-11-26T14:47:16.847744Z",
     "iopub.status.idle": "2020-11-26T14:47:22.144370Z",
     "shell.execute_reply": "2020-11-26T14:47:22.143822Z",
     "shell.execute_reply.started": "2020-11-26T14:47:16.847854Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(tfidf_indexes, 'tfidf_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:09:36.651964Z",
     "iopub.status.busy": "2020-11-26T15:09:36.651809Z",
     "iopub.status.idle": "2020-11-26T15:09:36.661952Z",
     "shell.execute_reply": "2020-11-26T15:09:36.661370Z",
     "shell.execute_reply.started": "2020-11-26T15:09:36.651946Z"
    }
   },
   "outputs": [],
   "source": [
    "class RankCalculator():\n",
    "    \n",
    "    # return [0-1]\n",
    "    def rank(book):\n",
    "        pass\n",
    "\n",
    "class ByTfidf(RankCalculator):\n",
    "    def __init__(self, tfidf_indexes):\n",
    "        self.tfidf_indexes = tfidf_indexes\n",
    "    \n",
    "    def rank(self, book, query, token_ids):\n",
    "        doc = book['index']\n",
    "        tfidf = 0\n",
    "        for token_id in token_ids:\n",
    "            tfidf += self.tfidf_indexes[token_id][doc]\n",
    "        return tfidf / np.sqrt(len(query.split()))\n",
    "    \n",
    "class ByRatingValue(RankCalculator):\n",
    "    def __init__(self, df):\n",
    "        self.max_rating = df['ratingValue'].max()\n",
    "        \n",
    "    def rank(self, book, query, token_ids):\n",
    "        return book['ratingValue'] / self.max_rating\n",
    "    \n",
    "class ByRatingCount(RankCalculator):\n",
    "    def __init__(self, df):\n",
    "        self.max_rating = df['ratingCount'].max()\n",
    "        \n",
    "    def rank(self, book, query, token_ids):\n",
    "        return book['ratingCount'] / self.max_rating\n",
    "    \n",
    "class ByTitleMatch(RankCalculator):\n",
    "    def rank(self, book, query, token_ids):\n",
    "        title_lenght = len(word_tokenize(book['bookTitle']))\n",
    "        matches = 0\n",
    "        for token in set(word_tokenize(query)):\n",
    "            if token in book['bookTitle'].lower():\n",
    "                matches += 1\n",
    "        return matches / title_lenght\n",
    "    \n",
    "class WeightedRanks(RankCalculator):\n",
    "    def __init__(self, calculators):\n",
    "        self.calculators = calculators\n",
    "        \n",
    "    def rank(self, book, query, token_ids):\n",
    "        total_weight = np.sum([weight for weight, _ in self.calculators])\n",
    "        return np.sum([calculator.rank(book, query, token_ids) * weight / total_weight for weight, calculator in self.calculators])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class RankedSearchEngine:\n",
    "    def __init__(self, df, term_indexes, inv_indexes, tfidf_indexes, simple_SE, score):\n",
    "        self.df = df\n",
    "        self.term_indexes = term_indexes\n",
    "        self.inv_indexes = inv_indexes\n",
    "        self.tfidf_indexes = tfidf_indexes\n",
    "        self.simple_SE = simple_SE\n",
    "        self.rank_calculator = rank_calculator\n",
    "        \n",
    "    def execute_query(self, query, k):\n",
    "        # First stem the query\n",
    "        ps = PorterStemmer()\n",
    "        query_tokens = set([ps.stem(w) for w in word_tokenize(query)])\n",
    "        \n",
    "        # Extract the token indexes from the vocabulary\n",
    "        tokens_ids = []\n",
    "        for token in query_tokens:\n",
    "            try:\n",
    "                tokens_ids.append(self.term_indexes[token])\n",
    "            except:\n",
    "                return\n",
    "        \n",
    "        # Compute the simple conjunctive query to get the books in which the query appears\n",
    "        conj_query = self.simple_SE.search(query)\n",
    "        \n",
    "        # Extract the documents id for these books\n",
    "        conj_query_ids = conj_query.index\n",
    "        # Compute the similiarity\n",
    "        conj_query['Similarity'] = conj_query.apply(lambda t: self.rank_calculator.rank(t, query, tokens_ids), axis=1)\n",
    "\n",
    "        # Use heaps to extract top k rows\n",
    "        conj_query_list = conj_query[['bookTitle', 'Plot', 'Url', 'Similarity']].values.tolist()\n",
    "        # return conj_query_list\n",
    "        heapq.heapify(conj_query_list)\n",
    "        max_k = heapq.nlargest(k, conj_query_list, key = lambda t: t[3])\n",
    "\n",
    "        # Convert back to dataframe to show it\n",
    "        max_k_df = pd.DataFrame(data=max_k, columns=['bookTitle', 'Plot', 'Url', 'Similarity'])\n",
    "\n",
    "        return max_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:11:15.986998Z",
     "iopub.status.busy": "2020-11-26T15:11:15.986823Z",
     "iopub.status.idle": "2020-11-26T15:11:16.002538Z",
     "shell.execute_reply": "2020-11-26T15:11:16.001902Z",
     "shell.execute_reply.started": "2020-11-26T15:11:15.986979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Warden</td>\n",
       "      <td>alic led normal life she wake find trap sick g...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33655366-t...</td>\n",
       "      <td>0.350603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "      <td>0.277220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Quillan Games</td>\n",
       "      <td>let the game begin quillan territori verg dest...</td>\n",
       "      <td>https://www.goodreads.com/book/show/215540.The...</td>\n",
       "      <td>0.249645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "      <td>0.225134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Truth</td>\n",
       "      <td>from new york time usa today bestsel author al...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16070018-t...</td>\n",
       "      <td>0.174925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Books of the South</td>\n",
       "      <td>march south ghastli battl tower charm black co...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2365730.Th...</td>\n",
       "      <td>0.173684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cage of Darkness</td>\n",
       "      <td>while travel fren allyssa odar hijack ruthless...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33893388-c...</td>\n",
       "      <td>0.162520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warcross</td>\n",
       "      <td>for million log everi day warcross game way li...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41014903-w...</td>\n",
       "      <td>0.150607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Becoming Noah Baxter</td>\n",
       "      <td>part two two part seri jay lili complet way on...</td>\n",
       "      <td>https://www.goodreads.com/book/show/18926659-b...</td>\n",
       "      <td>0.146844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "      <td>0.146466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bookTitle                                               Plot  \\\n",
       "0              The Warden  alic led normal life she wake find trap sick g...   \n",
       "1             Devil's Own  after surviv slaveri aiden macalpin noth thoug...   \n",
       "2       The Quillan Games  let the game begin quillan territori verg dest...   \n",
       "3        The Hunger Games  could surviv wild everi one make sure live see...   \n",
       "4                   Truth  from new york time usa today bestsel author al...   \n",
       "5  The Books of the South  march south ghastli battl tower charm black co...   \n",
       "6        Cage of Darkness  while travel fren allyssa odar hijack ruthless...   \n",
       "7                Warcross  for million log everi day warcross game way li...   \n",
       "8    Becoming Noah Baxter  part two two part seri jay lili complet way on...   \n",
       "9              Mockingjay  the final book ground break hunger game trilog...   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.goodreads.com/book/show/33655366-t...    0.350603  \n",
       "1  https://www.goodreads.com/book/show/8705483-de...    0.277220  \n",
       "2  https://www.goodreads.com/book/show/215540.The...    0.249645  \n",
       "3  https://www.goodreads.com/book/show/2767052-th...    0.225134  \n",
       "4  https://www.goodreads.com/book/show/16070018-t...    0.174925  \n",
       "5  https://www.goodreads.com/book/show/2365730.Th...    0.173684  \n",
       "6  https://www.goodreads.com/book/show/33893388-c...    0.162520  \n",
       "7  https://www.goodreads.com/book/show/41014903-w...    0.150607  \n",
       "8  https://www.goodreads.com/book/show/18926659-b...    0.146844  \n",
       "9  https://www.goodreads.com/book/show/7260188-mo...    0.146466  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_calculator = WeightedRanks([\n",
    "    (1, ByTfidf(tfidf_indexes)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "tfidf_se = RankedSearchEngine(df, term_indexes, inv_indexes, tfidf_indexes, simple_se, rank_calculator)\n",
    "\n",
    "tfidf_se.execute_query('survival games', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a new score!\n",
    "\n",
    "For this particular task, we didn't feel like a search engine like this could benefit from multiple type of information in the query. Instead, we tought about creating a new scoring function by analizing the reviews columns, not by over analyzing the query itself.\n",
    "\n",
    "Our scoring function is based on the fact that, probably, the most rated books are the most important ones; moreover, the user is probably most interested in the ones with an high number of ratings. Now there is an issue: which kind of book would you prefer to see, one which has a small amount of ratings but with perfect rating value, or one which has a score which is pretty high (not perfect), but with lots of ratings?\n",
    "\n",
    "For example, let's say we have three books in our query results, and we want to sort them by their ratings:\n",
    "\n",
    "- **Book 1**: ⭐⭐⭐⭐⭐ 5/5 (10 total ratings) $\\rightarrow$ 100%, 10 positive reviews, 0 negative reviews\n",
    "- **Book 2**: ⭐⭐⭐⭐✨ 4.8/5 (50 total ratings) $\\rightarrow$ 96%, 48 positive reviews, 2 negative reviews\n",
    "- **Book 3**: ⭐⭐⭐⭐✨ 4.65/5 (200 total ratings) $\\rightarrow$ 93%, 186 positive reviews, 14 negative reviews\n",
    "\n",
    "Which one should be considered the **best** book in terms of ratings?\n",
    "\n",
    "We probably all have the same confidence in saying that the more data we see, it gives us more confidence in a given rating. When we look at perfect ratings, more often than not they come from a tiny number of reviews, which makes it feel more plausible that things could have gone another way, and give a lower ratings. How can we make this intuition quantitative? How can we rationally reason about this trade-off? A good mathematical explanation about this is given by John Cook in his [blogpost](https://www.johndcook.com/blog/2011/09/27/bayesian-amazon/). However, we are not going to dive too much in its mathematical explanation (even if it is actually really interesting!).\n",
    "\n",
    "In our example, to get the best book, we need to use **Rule of succession**, a formula introduced by Laplace in the 18th century. This is basically used to answer the following question: if we repeat an experiment that we know can result in a success or failure, $n$ times independently, and get $s$ successes, and $n-s$ failures, then what is the probability that the next repetition will succeed? And the answer is:\n",
    "\n",
    "$$P(X_{{n+1}}=1\\mid X_{1}+\\cdots +X_{n}=s)= \\frac{s + 1}{n+2}.$$\n",
    "\n",
    "In the above example, it means that when we see the ratings, we should pretend like were 2 more reviews, one which is positive, one which is negative. For each book, this would result in the following:\n",
    "\n",
    "1) For **book 1**, we would have 11 positive ratings and 1 negative rating, which would give $\\frac{11}{12} \\approx 91.7\\%$.\n",
    "\n",
    "2) For **book 2**, we would have 49 positive ratings and 3 negative rating, which would give $\\frac{49}{52} \\approx 94.2\\%$.\n",
    "\n",
    "3) For **book 3**, we would have 187 positive ratings and 15 negative rating, which would give $\\frac{187}{202} \\approx 92.6\\%$.\n",
    "\n",
    "These probabilities we see here, would be the probabilities of having a good experience with those given books, and it is actually what we can say to infer that the second option would be the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T15:12:08.711149Z",
     "iopub.status.busy": "2020-11-26T15:12:08.710982Z",
     "iopub.status.idle": "2020-11-26T15:12:08.753048Z",
     "shell.execute_reply": "2020-11-26T15:12:08.752569Z",
     "shell.execute_reply.started": "2020-11-26T15:12:08.711130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "      <td>0.580531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "      <td>0.265922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>spark are ignit flame are spread and the capit...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6148028-ca...</td>\n",
       "      <td>0.250651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Quillan Games</td>\n",
       "      <td>let the game begin quillan territori verg dest...</td>\n",
       "      <td>https://www.goodreads.com/book/show/215540.The...</td>\n",
       "      <td>0.238758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wicked Games</td>\n",
       "      <td>abbi lewi never pictur surviv game show endur ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10719342-w...</td>\n",
       "      <td>0.229486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Warden</td>\n",
       "      <td>alic led normal life she wake find trap sick g...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33655366-t...</td>\n",
       "      <td>0.202725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "      <td>0.173697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Truth</td>\n",
       "      <td>from new york time usa today bestsel author al...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16070018-t...</td>\n",
       "      <td>0.156104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Books of the South</td>\n",
       "      <td>march south ghastli battl tower charm black co...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2365730.Th...</td>\n",
       "      <td>0.152318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cage of Darkness</td>\n",
       "      <td>while travel fren allyssa odar hijack ruthless...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33893388-c...</td>\n",
       "      <td>0.149313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bookTitle                                               Plot  \\\n",
       "0        The Hunger Games  could surviv wild everi one make sure live see...   \n",
       "1              Mockingjay  the final book ground break hunger game trilog...   \n",
       "2           Catching Fire  spark are ignit flame are spread and the capit...   \n",
       "3       The Quillan Games  let the game begin quillan territori verg dest...   \n",
       "4            Wicked Games  abbi lewi never pictur surviv game show endur ...   \n",
       "5              The Warden  alic led normal life she wake find trap sick g...   \n",
       "6             Devil's Own  after surviv slaveri aiden macalpin noth thoug...   \n",
       "7                   Truth  from new york time usa today bestsel author al...   \n",
       "8  The Books of the South  march south ghastli battl tower charm black co...   \n",
       "9        Cage of Darkness  while travel fren allyssa odar hijack ruthless...   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...    0.580531  \n",
       "1  https://www.goodreads.com/book/show/7260188-mo...    0.265922  \n",
       "2  https://www.goodreads.com/book/show/6148028-ca...    0.250651  \n",
       "3  https://www.goodreads.com/book/show/215540.The...    0.238758  \n",
       "4  https://www.goodreads.com/book/show/10719342-w...    0.229486  \n",
       "5  https://www.goodreads.com/book/show/33655366-t...    0.202725  \n",
       "6  https://www.goodreads.com/book/show/8705483-de...    0.173697  \n",
       "7  https://www.goodreads.com/book/show/16070018-t...    0.156104  \n",
       "8  https://www.goodreads.com/book/show/2365730.Th...    0.152318  \n",
       "9  https://www.goodreads.com/book/show/33893388-c...    0.149313  "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_calculator = WeightedRanks([\n",
    "    (8, ByTfidf(tfidf_indexes)),\n",
    "    (3, ByRatingValue(df)),\n",
    "    (10, ByRatingCount(df)),\n",
    "    (5, ByTitleMatch())\n",
    "])\n",
    "\n",
    "\n",
    "rnkd_SE = RankedSearchEngine(df, term_indexes, inv_indexes, tfidf_indexes, simple_se, rank_calculator)\n",
    "\n",
    "rnkd_SE.execute_query('survival games', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
