{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T10:00:32.923221Z",
     "iopub.status.busy": "2020-11-29T10:00:32.923035Z",
     "iopub.status.idle": "2020-11-29T10:00:34.139217Z",
     "shell.execute_reply": "2020-11-29T10:00:34.138842Z",
     "shell.execute_reply.started": "2020-11-29T10:00:32.923189Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import string\n",
    "import data_collector\n",
    "import parser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import heapq\n",
    "import re\n",
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of the books\n",
    "We already have the list of books in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both dirs, bests and links parameters to create the correct directories and download the txt containing all the html links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:16.098660Z",
     "iopub.status.busy": "2020-11-28T16:26:16.098469Z",
     "iopub.status.idle": "2020-11-28T16:26:16.101749Z",
     "shell.execute_reply": "2020-11-28T16:26:16.101103Z",
     "shell.execute_reply.started": "2020-11-28T16:26:16.098643Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(dirs=False, bests=False, links=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Crawl books\n",
    "We already have all the htmls in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both the books and fails parameters to download all the html pages and remove the ones with broken pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:16.589979Z",
     "iopub.status.busy": "2020-11-28T16:26:16.589278Z",
     "iopub.status.idle": "2020-11-28T16:26:16.598563Z",
     "shell.execute_reply": "2020-11-28T16:26:16.596131Z",
     "shell.execute_reply.started": "2020-11-28T16:26:16.589898Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(books=False, fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Parse downloaded pages\n",
    "Set to `True` the create parameter to parse the downloaded html pages and create the tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:19.801799Z",
     "iopub.status.busy": "2020-11-28T16:26:19.801645Z",
     "iopub.status.idle": "2020-11-28T16:26:19.804337Z",
     "shell.execute_reply": "2020-11-28T16:26:19.803784Z",
     "shell.execute_reply.started": "2020-11-28T16:26:19.801781Z"
    }
   },
   "outputs": [],
   "source": [
    "parser.create_tsv(create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:22.371273Z",
     "iopub.status.busy": "2020-11-28T16:26:22.371083Z",
     "iopub.status.idle": "2020-11-28T16:26:22.653460Z",
     "shell.execute_reply": "2020-11-28T16:26:22.653035Z",
     "shell.execute_reply.started": "2020-11-28T16:26:22.371256Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('parsed_books.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:22.654278Z",
     "iopub.status.busy": "2020-11-28T16:26:22.654159Z",
     "iopub.status.idle": "2020-11-28T16:26:22.661459Z",
     "shell.execute_reply": "2020-11-28T16:26:22.661014Z",
     "shell.execute_reply.started": "2020-11-28T16:26:22.654262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29959, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:23.116765Z",
     "iopub.status.busy": "2020-11-28T16:26:23.115917Z",
     "iopub.status.idle": "2020-11-28T16:26:23.149993Z",
     "shell.execute_reply": "2020-11-28T16:26:23.149317Z",
     "shell.execute_reply.started": "2020-11-28T16:26:23.116656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen Peeta Mellark Cato (Hunger Ga...</td>\n",
       "      <td>District 12, Panem Capitol, Panem Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>September 2004</td>\n",
       "      <td>Sirius Black Draco Malfoy Ron Weasley Petunia ...</td>\n",
       "      <td>Hogwarts School of Witchcraft and Wizardry Lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>May 23rd 2006</td>\n",
       "      <td>Scout Finch Atticus Finch Jem Finch Arthur Rad...</td>\n",
       "      <td>Maycomb, Alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>October 10th 2000</td>\n",
       "      <td>Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...</td>\n",
       "      <td>United Kingdom Derbyshire, England England Her...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>September 6th 2006</td>\n",
       "      <td>Edward Cullen Jacob Black Laurent Renee Bella ...</td>\n",
       "      <td>Forks, Washington Phoenix, Arizona Washington ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  Suzanne Collins         4.33    6408798.0     172554.0   \n",
       "1     J.K. Rowling         4.50    2525157.0      42734.0   \n",
       "2       Harper Lee         4.28    4527405.0      91802.0   \n",
       "3      Jane Austen         4.26    3017830.0      67811.0   \n",
       "4  Stephenie Meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  Could you survive on your own in the wild, wit...          374.0   \n",
       "1  There is a door at the end of a silent corrido...          870.0   \n",
       "2  The unforgettable novel of a childhood in a sl...          324.0   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...          279.0   \n",
       "4  About three things I was absolutely positive.F...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen Peeta Mellark Cato (Hunger Ga...   \n",
       "1       September 2004  Sirius Black Draco Malfoy Ron Weasley Petunia ...   \n",
       "2        May 23rd 2006  Scout Finch Atticus Finch Jem Finch Arthur Rad...   \n",
       "3    October 10th 2000  Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...   \n",
       "4   September 6th 2006  Edward Cullen Jacob Black Laurent Renee Bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0            District 12, Panem Capitol, Panem Panem   \n",
       "1  Hogwarts School of Witchcraft and Wizardry Lon...   \n",
       "2                                   Maycomb, Alabama   \n",
       "3  United Kingdom Derbyshire, England England Her...   \n",
       "4  Forks, Washington Phoenix, Arizona Washington ...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset cleaning [preliminary steps]\n",
    "Before actually jumping into the work itself, we want our dataframe to be clean, meaning that there are some preliminary steps we need to perform on it. First of all, missing data is something we should pay attention to. Lot's of rows are going to have missing data somewhere, and dealing with missing data it's not that nice. Notice that this will include different strategies for each of the column we will be considering (more details below). Then there is the problem with punctuation, stopwords, stems and so on so forth, so basic text data preprocessing. Let's make a brief recap:\n",
    "\n",
    "1. **Missing data**\n",
    "    - `bookTitle`: if a book is missing the title, then we can safely just remove the instance. In fact, books that are missing the title are actually missing all the informations, meaning that there is a problem with the GoodReads specific link. Also, even if a book was missing just the title, we wouldn't have a way to refer to it, thus it wouldn't be really useful considering we're building a search engine.\n",
    "    - `bookSeries`, `Authors`, `Plot`, `PublishingDate`, `Characters`, `Setting`: if a book is missing one of the above mentioned columns, we can still include the book in the data, since the search engine could for example work with just the title. Obviously, we cannot just leave the values missing, since it would be really hard to perform any operation on that. These are all text columns, therefore the best way to address the missing values prolem is to replace NaNs with empty strings.\n",
    "    - `ratingValue`, `NumberofPages`: TODO?\n",
    "2. **Text data preprocessing**\n",
    "    - Punctuation removal: this is the first step we want to perform, since it is going to make the next steps much easier (e.g., language detection will be easier if there aren't plots composed just by punctuation symbols).\n",
    "    - Language detection: before doing anything else, we want to remove the books that present the books for which the plot isn't in english.\n",
    "    - Stopwords removal (of the `Plot` column only)\n",
    "    - Stemming (of the `Plot` column only)\n",
    "    - Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title\n",
    "There are 774 books that are completely empty, and these corresponds to the ones that are missing the `bookTitle` column. If you give a look at the url, you can see that these are not given by our python script to download and parse the books, but actually from the fact that the link is broken. Also, you can see that all the books that are missing the `bookTitle` are also missing all the remaining data.\n",
    "\n",
    "This means that we can safely just remove all the rows that are missing the `bookTitle` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:27.844306Z",
     "iopub.status.busy": "2020-11-28T16:26:27.843950Z",
     "iopub.status.idle": "2020-11-28T16:26:27.861432Z",
     "shell.execute_reply": "2020-11-28T16:26:27.860982Z",
     "shell.execute_reply.started": "2020-11-28T16:26:27.844264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 774 instances that are missing the `bookTitle` column.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40937505\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528535\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528544\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40941582\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/5295735\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bookTitle bookSeries bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "311        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "370        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "379        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "789        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "1141       NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Plot  numberOfPages PublishingDate Characters Setting  \\\n",
       "311   NaN            NaN            NaN        NaN     NaN   \n",
       "370   NaN            NaN            NaN        NaN     NaN   \n",
       "379   NaN            NaN            NaN        NaN     NaN   \n",
       "789   NaN            NaN            NaN        NaN     NaN   \n",
       "1141  NaN            NaN            NaN        NaN     NaN   \n",
       "\n",
       "                                                   Url  \n",
       "311   https://www.goodreads.com/book/show/40937505\\r\\n  \n",
       "370   https://www.goodreads.com/book/show/30528535\\r\\n  \n",
       "379   https://www.goodreads.com/book/show/30528544\\r\\n  \n",
       "789   https://www.goodreads.com/book/show/40941582\\r\\n  \n",
       "1141   https://www.goodreads.com/book/show/5295735\\r\\n  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.book_title_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:29.437236Z",
     "iopub.status.busy": "2020-11-28T16:26:29.437016Z",
     "iopub.status.idle": "2020-11-28T16:26:29.447829Z",
     "shell.execute_reply": "2020-11-28T16:26:29.447233Z",
     "shell.execute_reply.started": "2020-11-28T16:26:29.437211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove empty books\n",
    "df = df[(df['bookTitle'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text data\n",
    "To handle missing data in the preprocessing, we'll need to convert NaNs to empty strings, for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:32.431504Z",
     "iopub.status.busy": "2020-11-28T16:26:32.431256Z",
     "iopub.status.idle": "2020-11-28T16:26:32.458128Z",
     "shell.execute_reply": "2020-11-28T16:26:32.457276Z",
     "shell.execute_reply.started": "2020-11-28T16:26:32.431475Z"
    }
   },
   "outputs": [],
   "source": [
    "str_columns = ['bookSeries', 'bookAuthors', 'Plot', 'PublishingDate', 'Characters', 'Setting']\n",
    "\n",
    "for col in str_columns:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:45.720841Z",
     "iopub.status.busy": "2020-11-28T16:26:45.720170Z",
     "iopub.status.idle": "2020-11-28T16:26:47.157823Z",
     "shell.execute_reply": "2020-11-28T16:26:47.157300Z",
     "shell.execute_reply.started": "2020-11-28T16:26:45.720758Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    if col != 'bookSeries':\n",
    "        df[col] = df[col].apply(functions.remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:11:07.055797Z",
     "iopub.status.busy": "2020-11-22T13:11:07.055640Z",
     "iopub.status.idle": "2020-11-22T13:11:07.074512Z",
     "shell.execute_reply": "2020-11-22T13:11:07.073991Z",
     "shell.execute_reply.started": "2020-11-22T13:11:07.055779Z"
    }
   },
   "source": [
    "#### Language detection\n",
    "There are four possibilities `Plot` column of a given book:\n",
    "1. It is written in english\n",
    "2. It is written in another language\n",
    "3. It is empty\n",
    "4. It contains symbols, numbers, and so on\n",
    "\n",
    "We want to keep only the ones written in english or empty, so we are just going to discard the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:26:52.425722Z",
     "iopub.status.busy": "2020-11-28T16:26:52.425012Z",
     "iopub.status.idle": "2020-11-28T16:28:43.984186Z",
     "shell.execute_reply": "2020-11-28T16:28:43.983709Z",
     "shell.execute_reply.started": "2020-11-28T16:26:52.425638Z"
    }
   },
   "outputs": [],
   "source": [
    "df['plot_lang'] = df['Plot'].apply(functions.language_det)\n",
    "\n",
    "df = df[df['plot_lang'] == 'en'].drop(columns=['plot_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:28:43.985069Z",
     "iopub.status.busy": "2020-11-28T16:28:43.984914Z",
     "iopub.status.idle": "2020-11-28T16:28:43.988724Z",
     "shell.execute_reply": "2020-11-28T16:28:43.988045Z",
     "shell.execute_reply.started": "2020-11-28T16:28:43.985053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26125, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords removal\n",
    "We are not going to perform stopwords removal on all the columns, since we could remove important things (e.g., we don't want to remove anything from the names of the characters). The only column on which stopwords removal is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:28:43.990061Z",
     "iopub.status.busy": "2020-11-28T16:28:43.989915Z",
     "iopub.status.idle": "2020-11-28T16:28:59.576350Z",
     "shell.execute_reply": "2020-11-28T16:28:59.575851Z",
     "shell.execute_reply.started": "2020-11-28T16:28:43.990044Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(functions.remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "As for the stopwords removal, the only column on which stemming is necessary is `Plot`. Notice that we're using the stemming function twice, since there are words that are stemmed in really similar roots (we noticed that there are words that are either stemmed to *games* or *game*). This shouldn't be the case! If we apply stemming again, we should solve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:28:59.577457Z",
     "iopub.status.busy": "2020-11-28T16:28:59.577307Z",
     "iopub.status.idle": "2020-11-28T16:30:21.026685Z",
     "shell.execute_reply": "2020-11-28T16:30:21.026214Z",
     "shell.execute_reply.started": "2020-11-28T16:28:59.577421Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(functions.stemming)\n",
    "df['Plot'] = df['Plot'].apply(functions.stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:16:37.617866Z",
     "iopub.status.busy": "2020-11-22T15:16:37.617156Z",
     "iopub.status.idle": "2020-11-22T15:17:23.722941Z",
     "shell.execute_reply": "2020-11-22T15:17:23.722477Z",
     "shell.execute_reply.started": "2020-11-22T15:16:37.617782Z"
    }
   },
   "source": [
    "#### Lowercase\n",
    "On the other hand, we want all the string columns to be lowercase, so that our search engine won't have problems with upper/lower case differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:30:21.027533Z",
     "iopub.status.busy": "2020-11-28T16:30:21.027382Z",
     "iopub.status.idle": "2020-11-28T16:30:21.074909Z",
     "shell.execute_reply": "2020-11-28T16:30:21.074408Z",
     "shell.execute_reply.started": "2020-11-28T16:30:21.027515Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(lambda w: w.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:30:21.108635Z",
     "iopub.status.busy": "2020-11-28T16:30:21.108463Z",
     "iopub.status.idle": "2020-11-28T16:30:21.660151Z",
     "shell.execute_reply": "2020-11-28T16:30:21.659631Z",
     "shell.execute_reply.started": "2020-11-28T16:30:21.108597Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True).reset_index()\n",
    "\n",
    "df.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:30:21.661478Z",
     "iopub.status.busy": "2020-11-28T16:30:21.661337Z",
     "iopub.status.idle": "2020-11-28T16:30:40.678999Z",
     "shell.execute_reply": "2020-11-28T16:30:40.678465Z",
     "shell.execute_reply.started": "2020-11-28T16:30:21.661461Z"
    }
   },
   "outputs": [],
   "source": [
    "# term_indexes = functions.term_index(df['Plot'])\n",
    "# inv_indexes = functions.inverted_index(df['Plot'], term_indexes)\n",
    "\n",
    "# functions.save_obj(term_indexes, 'vocabulary')\n",
    "# functions.save_obj(inv_indexes, 'inverted_index')\n",
    "\n",
    "term_indexes = functions.load_obj('vocabulary')\n",
    "inv_indexes = functions.load_obj('inverted_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:30:40.679793Z",
     "iopub.status.busy": "2020-11-28T16:30:40.679661Z",
     "iopub.status.idle": "2020-11-28T16:30:40.690284Z",
     "shell.execute_reply": "2020-11-28T16:30:40.689821Z",
     "shell.execute_reply.started": "2020-11-28T16:30:40.679775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>spark are ignit flame are spread and the capit...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6148028-ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Legend</td>\n",
       "      <td>what western unit state home republ nation per...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9275658-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>The Magus</td>\n",
       "      <td>thi dare literari thriller rich erot suspen on...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16286.The_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25066</th>\n",
       "      <td>The Manhattan Hunt Club</td>\n",
       "      <td>in manhattan hunt club john saul plumb depth m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6553.The_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25530</th>\n",
       "      <td>Love's Forbidden Flower</td>\n",
       "      <td>plea note thi new adult romanc novel involv tw...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16189423-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25805</th>\n",
       "      <td>The Southpaw</td>\n",
       "      <td>the southpaw stori come age america way baseb ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/413736.The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25826</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26063</th>\n",
       "      <td>Indian Hill</td>\n",
       "      <td>a michael talbot adventur thi first stori ordi...</td>\n",
       "      <td>https://www.goodreads.com/book/show/13305176-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bookTitle  \\\n",
       "0             The Hunger Games   \n",
       "221              Catching Fire   \n",
       "319                 Mockingjay   \n",
       "337                     Legend   \n",
       "652                  The Magus   \n",
       "...                        ...   \n",
       "25066  The Manhattan Hunt Club   \n",
       "25530  Love's Forbidden Flower   \n",
       "25805             The Southpaw   \n",
       "25826              Devil's Own   \n",
       "26063              Indian Hill   \n",
       "\n",
       "                                                    Plot  \\\n",
       "0      could surviv wild everi one make sure live see...   \n",
       "221    spark are ignit flame are spread and the capit...   \n",
       "319    the final book ground break hunger game trilog...   \n",
       "337    what western unit state home republ nation per...   \n",
       "652    thi dare literari thriller rich erot suspen on...   \n",
       "...                                                  ...   \n",
       "25066  in manhattan hunt club john saul plumb depth m...   \n",
       "25530  plea note thi new adult romanc novel involv tw...   \n",
       "25805  the southpaw stori come age america way baseb ...   \n",
       "25826  after surviv slaveri aiden macalpin noth thoug...   \n",
       "26063  a michael talbot adventur thi first stori ordi...   \n",
       "\n",
       "                                                     Url  \n",
       "0      https://www.goodreads.com/book/show/2767052-th...  \n",
       "221    https://www.goodreads.com/book/show/6148028-ca...  \n",
       "319    https://www.goodreads.com/book/show/7260188-mo...  \n",
       "337    https://www.goodreads.com/book/show/9275658-le...  \n",
       "652    https://www.goodreads.com/book/show/16286.The_...  \n",
       "...                                                  ...  \n",
       "25066  https://www.goodreads.com/book/show/6553.The_M...  \n",
       "25530  https://www.goodreads.com/book/show/16189423-l...  \n",
       "25805  https://www.goodreads.com/book/show/413736.The...  \n",
       "25826  https://www.goodreads.com/book/show/8705483-de...  \n",
       "26063  https://www.goodreads.com/book/show/13305176-i...  \n",
       "\n",
       "[112 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_SE = functions.SimpleSearchEngine(df, term_indexes, inv_indexes)\n",
    "\n",
    "simple_SE.execute_query('survival games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:30:40.691020Z",
     "iopub.status.busy": "2020-11-28T16:30:40.690891Z",
     "iopub.status.idle": "2020-11-28T16:31:01.215616Z",
     "shell.execute_reply": "2020-11-28T16:31:01.213363Z",
     "shell.execute_reply.started": "2020-11-28T16:30:40.691003Z"
    }
   },
   "outputs": [],
   "source": [
    "# tfidf_indexes = functions.tfidf_inv_indexes(df['Plot'], term_indexes, inv_indexes)\n",
    "\n",
    "# functions.save_obj(tfidf_indexes, 'tfidf_index')\n",
    "\n",
    "tfidf_indexes = functions.load_obj('tfidf_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:31:01.217845Z",
     "iopub.status.busy": "2020-11-28T16:31:01.217345Z",
     "iopub.status.idle": "2020-11-28T16:31:01.240764Z",
     "shell.execute_reply": "2020-11-28T16:31:01.240204Z",
     "shell.execute_reply.started": "2020-11-28T16:31:01.217782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Warden</td>\n",
       "      <td>alic led normal life she wake find trap sick g...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33655366-t...</td>\n",
       "      <td>0.350581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "      <td>0.277348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Quillan Games</td>\n",
       "      <td>let the game beginquillan territori verg destr...</td>\n",
       "      <td>https://www.goodreads.com/book/show/215540.The...</td>\n",
       "      <td>0.247555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "      <td>0.225212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Truth</td>\n",
       "      <td>from new york time usa today bestsel author al...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16070018-t...</td>\n",
       "      <td>0.174882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Books of the South</td>\n",
       "      <td>march south ghastli battl tower charm black co...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2365730.Th...</td>\n",
       "      <td>0.173746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cage of Darkness</td>\n",
       "      <td>while travel fren allyssa odar hijack ruthless...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33893388-c...</td>\n",
       "      <td>0.162628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warcross</td>\n",
       "      <td>for million log everi day warcross game way li...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41014903-w...</td>\n",
       "      <td>0.150790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Becoming Noah Baxter</td>\n",
       "      <td>part two two part seri jay lili complet way on...</td>\n",
       "      <td>https://www.goodreads.com/book/show/18926659-b...</td>\n",
       "      <td>0.146792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "      <td>0.146585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bookTitle                                               Plot  \\\n",
       "0              The Warden  alic led normal life she wake find trap sick g...   \n",
       "1             Devil's Own  after surviv slaveri aiden macalpin noth thoug...   \n",
       "2       The Quillan Games  let the game beginquillan territori verg destr...   \n",
       "3        The Hunger Games  could surviv wild everi one make sure live see...   \n",
       "4                   Truth  from new york time usa today bestsel author al...   \n",
       "5  The Books of the South  march south ghastli battl tower charm black co...   \n",
       "6        Cage of Darkness  while travel fren allyssa odar hijack ruthless...   \n",
       "7                Warcross  for million log everi day warcross game way li...   \n",
       "8    Becoming Noah Baxter  part two two part seri jay lili complet way on...   \n",
       "9              Mockingjay  the final book ground break hunger game trilog...   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.goodreads.com/book/show/33655366-t...    0.350581  \n",
       "1  https://www.goodreads.com/book/show/8705483-de...    0.277348  \n",
       "2  https://www.goodreads.com/book/show/215540.The...    0.247555  \n",
       "3  https://www.goodreads.com/book/show/2767052-th...    0.225212  \n",
       "4  https://www.goodreads.com/book/show/16070018-t...    0.174882  \n",
       "5  https://www.goodreads.com/book/show/2365730.Th...    0.173746  \n",
       "6  https://www.goodreads.com/book/show/33893388-c...    0.162628  \n",
       "7  https://www.goodreads.com/book/show/41014903-w...    0.150790  \n",
       "8  https://www.goodreads.com/book/show/18926659-b...    0.146792  \n",
       "9  https://www.goodreads.com/book/show/7260188-mo...    0.146585  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_function = functions.ByTfidf(tfidf_indexes)\n",
    "\n",
    "tfidf_SE = functions.RankedSearchEngine(df, term_indexes, inv_indexes, tfidf_indexes, simple_SE, scoring_function)\n",
    "\n",
    "tfidf_SE.execute_query('survival games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a new score!\n",
    "\n",
    "For this particular task, we didn't feel like a search engine like this could benefit from multiple type of information in the query. Instead, we tought about creating a new scoring function by analizing ratings value, ratings count and book title. In fact, the vast majority of times the user is more inclined in doing particular task in a single query, instead of adding more fields to the query itself. This means that a user probably prefers to write the name of the book or just some words to describe it, and then he just waits for the books that he wants to appear. In order to do that, we need to keep in mind that more often than not a user is interested in the most famous books, so the ones that have a really high number of ratings.\n",
    "\n",
    "Also, it is probably optimal to give some value to the fact that a book is well written, and therefore that it has good ratings. Unfortunately, in our opinion the rating value isn't really telling, since it is often the case that a user either gives a max score to an item, or he gives the worst. Also, we need to keep in mind that we're considering a list of so-called \"best books\", so they probably all have good ratings (or at least the vast majority of them). We can analyze this trend, by looking at the `ratingValue` column. As we can see from the below cell, the vast majority of books have a value between 4 and 5, just one slot. This means that the weight we are going to give to this factor is going to be really low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:31:01.241835Z",
     "iopub.status.busy": "2020-11-28T16:31:01.241675Z",
     "iopub.status.idle": "2020-11-28T16:31:01.268905Z",
     "shell.execute_reply": "2020-11-28T16:31:01.268443Z",
     "shell.execute_reply.started": "2020-11-28T16:31:01.241818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11080 books with rating value between 0 and 4\n",
      "There are 14559 books with rating value greater than 4\n"
     ]
    }
   ],
   "source": [
    "functions.rating_value_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it comes the book title: we need to give value to the title column, since we want to keep in mind that if a user search for a word (or multiple words) that appears in one book title, he's probably searching for that book. For this reason, we used an exact match search in the book title, meaning that for each word in the query, we give value to this kind of match if and only if the word appears in a book title. Obviously, if a book has a really long title, this value should decrease, because it becomes easier to match a word in that given title.\n",
    "\n",
    "Finally, we still wanted to keep the tfidf cosin similiarity, since it is important to mantain some kind of check between the query and the plot, and this seemed like the best option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together\n",
    "1) **TfIdf** ($\\mathrm{tfidf}$): like before, we will use the cosin similiarity between the tfidf of the query and the books ones.\n",
    "\n",
    "2) **Rating Value** ($\\mathrm{R_V}$): we are going to extract a value between 0 and 1, which will be the rating value for a particular book over the max rating value.\n",
    "\n",
    "3) **Rating Count** ($\\mathrm{R_C}$): we are going to extract a value between 0 and 1, which will be the rating count for a particular book over the max rating count.\n",
    "\n",
    "4) **Book Title Match** ($\\mathrm{T_M}$): we are going to extract a value between 0 and 1, which will be the number of query words found in a given book title over the number of words in the book title.\n",
    "\n",
    "Finally, we are going to use a weighted sum. The new ranking score for a query $q$ and a given book $b_i$ will look something like this:\n",
    "\n",
    "$$\\mathrm{Rnk}(q, b_i) = \\frac{25 \\cdot \\mathrm{tfidf}(q, b_i) + 10 \\cdot \\mathrm{R_V}(q, b_i) + 35 \\cdot \\mathrm{R_C}(q, b_i) + 30 \\cdot \\mathrm{T_M}(q, b_i)}{25 + 10 + 35 + 30}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T16:31:01.269716Z",
     "iopub.status.busy": "2020-11-28T16:31:01.269585Z",
     "iopub.status.idle": "2020-11-28T16:31:01.330829Z",
     "shell.execute_reply": "2020-11-28T16:31:01.330440Z",
     "shell.execute_reply.started": "2020-11-28T16:31:01.269699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "      <td>0.558885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wicked Games</td>\n",
       "      <td>abbi lewi never pictur surviv game show endur ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10719342-w...</td>\n",
       "      <td>0.263272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Quillan Games</td>\n",
       "      <td>let the game beginquillan territori verg destr...</td>\n",
       "      <td>https://www.goodreads.com/book/show/215540.The...</td>\n",
       "      <td>0.246734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "      <td>0.233585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>spark are ignit flame are spread and the capit...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6148028-ca...</td>\n",
       "      <td>0.222396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Warden</td>\n",
       "      <td>alic led normal life she wake find trap sick g...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33655366-t...</td>\n",
       "      <td>0.169847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "      <td>0.145949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Truth</td>\n",
       "      <td>from new york time usa today bestsel author al...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16070018-t...</td>\n",
       "      <td>0.132436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Books of the South</td>\n",
       "      <td>march south ghastli battl tower charm black co...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2365730.Th...</td>\n",
       "      <td>0.129155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cage of Darkness</td>\n",
       "      <td>while travel fren allyssa odar hijack ruthless...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33893388-c...</td>\n",
       "      <td>0.126727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bookTitle                                               Plot  \\\n",
       "0        The Hunger Games  could surviv wild everi one make sure live see...   \n",
       "1            Wicked Games  abbi lewi never pictur surviv game show endur ...   \n",
       "2       The Quillan Games  let the game beginquillan territori verg destr...   \n",
       "3              Mockingjay  the final book ground break hunger game trilog...   \n",
       "4           Catching Fire  spark are ignit flame are spread and the capit...   \n",
       "5              The Warden  alic led normal life she wake find trap sick g...   \n",
       "6             Devil's Own  after surviv slaveri aiden macalpin noth thoug...   \n",
       "7                   Truth  from new york time usa today bestsel author al...   \n",
       "8  The Books of the South  march south ghastli battl tower charm black co...   \n",
       "9        Cage of Darkness  while travel fren allyssa odar hijack ruthless...   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...    0.558885  \n",
       "1  https://www.goodreads.com/book/show/10719342-w...    0.263272  \n",
       "2  https://www.goodreads.com/book/show/215540.The...    0.246734  \n",
       "3  https://www.goodreads.com/book/show/7260188-mo...    0.233585  \n",
       "4  https://www.goodreads.com/book/show/6148028-ca...    0.222396  \n",
       "5  https://www.goodreads.com/book/show/33655366-t...    0.169847  \n",
       "6  https://www.goodreads.com/book/show/8705483-de...    0.145949  \n",
       "7  https://www.goodreads.com/book/show/16070018-t...    0.132436  \n",
       "8  https://www.goodreads.com/book/show/2365730.Th...    0.129155  \n",
       "9  https://www.goodreads.com/book/show/33893388-c...    0.126727  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_calculator = functions.WeightedRanks([\n",
    "    (25, functions.ByTfidf(tfidf_indexes)),\n",
    "    (10, functions.ByRatingValue(df)),\n",
    "    (35, functions.ByRatingCount(df)),\n",
    "    (30, functions.ByTitleMatch()),\n",
    "])\n",
    "\n",
    "\n",
    "rnkd_SE = functions.RankedSearchEngine(df, term_indexes, inv_indexes, tfidf_indexes, simple_SE, rank_calculator)\n",
    "\n",
    "rnkd_SE.execute_query('survival games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algorithmic Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Recursive implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T10:00:16.960172Z",
     "iopub.status.busy": "2020-11-29T10:00:16.959617Z",
     "iopub.status.idle": "2020-11-29T10:00:16.966425Z",
     "shell.execute_reply": "2020-11-29T10:00:16.965846Z",
     "shell.execute_reply.started": "2020-11-29T10:00:16.960022Z"
    }
   },
   "outputs": [],
   "source": [
    "def helper(arr, pos):\n",
    "    prev_elements = [i for i in range(pos) if arr[i] < arr[pos]]\n",
    "    if len(prev_elements) == 0:\n",
    "        return 1\n",
    "    return 1 + max([helper(arr, i) for i in prev_elements])\n",
    "\n",
    "\n",
    "def lis(arr):\n",
    "    return max([helper(arr, i) for i in range(len(arr))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 1:**\n",
    "\n",
    "As we can see, the algorithm does what it should do with small strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T10:00:29.759639Z",
     "iopub.status.busy": "2020-11-29T10:00:29.759182Z",
     "iopub.status.idle": "2020-11-29T10:00:29.801132Z",
     "shell.execute_reply": "2020-11-29T10:00:29.800689Z",
     "shell.execute_reply.started": "2020-11-29T10:00:29.759582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'CADFECEILGJHABNOFPSTIRYOEABILCNR'\n",
    "lis(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T10:03:50.985499Z",
     "iopub.status.busy": "2020-11-29T10:03:50.985312Z",
     "iopub.status.idle": "2020-11-29T10:03:50.988769Z",
     "shell.execute_reply": "2020-11-29T10:03:50.988431Z",
     "shell.execute_reply.started": "2020-11-29T10:03:50.985481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'ABABABAB'\n",
    "lis(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 2:**\n",
    "\n",
    "Problem raises when there are consecutive alphabetical characters. That is, in fact, the worst possible case. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T12:36:57.841296Z",
     "iopub.status.busy": "2020-11-29T12:36:57.841094Z",
     "iopub.status.idle": "2020-11-29T12:37:42.177589Z",
     "shell.execute_reply": "2020-11-29T12:37:42.177071Z",
     "shell.execute_reply.started": "2020-11-29T12:36:57.841249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for execution: 44.33s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "s = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "start = time.time()\n",
    "lis(s)\n",
    "end = time.time()\n",
    "\n",
    "print('Time for execution: {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with just 26 characters in an alphabetical order, our algorithm takes a pretty long time. If we try to use this algorithm with something even longer (e.g., a list `[1, 2, 3, ..., 100]`; notice that the algorithm also works with lists!) it wouldn't actually end in a reasonable time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T19:16:19.835224Z",
     "iopub.status.busy": "2020-11-29T19:16:19.835059Z",
     "iopub.status.idle": "2020-11-29T19:16:19.971449Z",
     "shell.execute_reply": "2020-11-29T19:16:19.970807Z",
     "shell.execute_reply.started": "2020-11-29T19:16:19.835204Z"
    }
   },
   "source": [
    "<img src='tree.png' class='center' width=\"1000\" />\n",
    "\n",
    "The previous figure represent the number of nodes at each step. We can easily see that at each step we have that, representing with $f(i)$ the number of nodes at step $i$:\n",
    "\n",
    "$$f(i) = 1 + f(n - 1) + f(n - 2) + \\dots + f(1) = 1 + \\sum_{j = 0}^{i} f(j)$$\n",
    "\n",
    "Now, we can prove that the total number of nodes is exactly $2^{n - 1}$. If we try this for small numbers, this is trivial; if we want to prove this, we can use induction:\n",
    "\n",
    "At step 1, we obviously have $2^0 = 1$ nodes;\n",
    "\n",
    "Let's assume that this is true for $n$, we need to prove that this implies that this formula is also true for $n + 1$. Let's compute $f(n + 1)$ and see what we can do:\n",
    "\n",
    "\\begin{align}\n",
    "    f(n + 1) & = 1 + \\sum_{i = 0}^{n} f(i) = 1 + \\sum_{i = 0}^{n} f(i) = 1 + \\sum_{i = 0}^{n} 2^{i - 1} \\\\\n",
    "    & = 1 + \\sum_{i = 1}^{n + 1} 2^{i} = 1 + \\frac{2^n - 1}{2 - 1} = 2^n = 2^{(n + 1) - 1} \\\\\n",
    "\\end{align}\n",
    "\n",
    "which is exactly what we would expect.\n",
    "\n",
    "Now, each node has complexity $O\\,(n)$ in the worst case, since there is the computation of the previous elements. Having an exponential number of nodes, this means that the total complexity is also exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Dynamic implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T12:26:56.841208Z",
     "iopub.status.busy": "2020-11-29T12:26:56.841017Z",
     "iopub.status.idle": "2020-11-29T12:26:56.845103Z",
     "shell.execute_reply": "2020-11-29T12:26:56.844544Z",
     "shell.execute_reply.started": "2020-11-29T12:26:56.841189Z"
    }
   },
   "outputs": [],
   "source": [
    "def dyn_lis(arr):\n",
    "    if len(arr) == 1:\n",
    "        return 1\n",
    "    fin_max = 1\n",
    "    prev_lis = [1] * len(arr)\n",
    "    for i in range(1, len(arr)):\n",
    "        curr_max = 1\n",
    "        for j in range(i):\n",
    "            if arr[i] > arr[j]:\n",
    "                curr_max = max(curr_max, prev_lis[j] + 1)\n",
    "            prev_lis[i] = curr_max\n",
    "    return max(prev_lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "Even if this is not the best solution out there (this takes $O \\, (n^2)$, best solution takes $O \\, (n \\log n)$), we can see that this is feasible when working with reasonable inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T12:36:43.050157Z",
     "iopub.status.busy": "2020-11-29T12:36:43.049994Z",
     "iopub.status.idle": "2020-11-29T12:36:43.223666Z",
     "shell.execute_reply": "2020-11-29T12:36:43.223110Z",
     "shell.execute_reply.started": "2020-11-29T12:36:43.050139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest increasing for `s` has lenght 11\n",
      "Time for execution for `big_s` = 0.17s\n"
     ]
    }
   ],
   "source": [
    "s = 'CADFECEILGJHABNOFPSTIRYOEABILCNR'\n",
    "print('Longest increasing for `s` has lenght {}'.format(dyn_lis(s)))\n",
    "\n",
    "big_s = range(1000)\n",
    "start = time.time()\n",
    "dyn_lis(big_s)\n",
    "end = time.time()\n",
    "\n",
    "print('Time for execution for `big_s` = {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, outside of the loop there are two functions (`len()` and `max()`) which both takes linear time $O(n)$. Inside the nested loops, there is an `if` statement, which takes $O(1)$, and since we are doing $n^2$ iterations in total, we have $O(n^2)$ for the `for` loops. Notice that the `max` in the `if` is just between two elements, so it only takes $O(1)$.\n",
    "\n",
    "Therefore, we can conclude that the total time complexity is $O(n^2)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
