{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:55:08.993216Z",
     "iopub.status.busy": "2020-11-23T18:55:08.992596Z",
     "iopub.status.idle": "2020-11-23T18:55:09.766959Z",
     "shell.execute_reply": "2020-11-23T18:55:09.766448Z",
     "shell.execute_reply.started": "2020-11-23T18:55:08.993137Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import string\n",
    "import data_collector\n",
    "import parser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of the books\n",
    "We already have the list of books in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both dirs, bests and links parameters to create the correct directories and download the txt containing all the html links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.588151Z",
     "iopub.status.busy": "2020-11-22T22:28:10.587988Z",
     "iopub.status.idle": "2020-11-22T22:28:10.591041Z",
     "shell.execute_reply": "2020-11-22T22:28:10.590475Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.588099Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(dirs=False, bests=False, links=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Crawl books\n",
    "We already have all the htmls in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both the books and fails parameters to download all the html pages and remove the ones with broken pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.593990Z",
     "iopub.status.busy": "2020-11-22T22:28:10.593855Z",
     "iopub.status.idle": "2020-11-22T22:28:10.634453Z",
     "shell.execute_reply": "2020-11-22T22:28:10.633377Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.593972Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(books=False, fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Parse downloaded pages\n",
    "Set to `True` the create parameter to parse the downloaded html pages and create the tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.635794Z",
     "iopub.status.busy": "2020-11-22T22:28:10.635569Z",
     "iopub.status.idle": "2020-11-22T22:28:10.648884Z",
     "shell.execute_reply": "2020-11-22T22:28:10.648186Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.635759Z"
    }
   },
   "outputs": [],
   "source": [
    "parser.create_tsv(create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.650018Z",
     "iopub.status.busy": "2020-11-22T22:28:10.649791Z",
     "iopub.status.idle": "2020-11-22T22:28:10.943680Z",
     "shell.execute_reply": "2020-11-22T22:28:10.943198Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.649989Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('parsed_books.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.944542Z",
     "iopub.status.busy": "2020-11-22T22:28:10.944358Z",
     "iopub.status.idle": "2020-11-22T22:28:10.954676Z",
     "shell.execute_reply": "2020-11-22T22:28:10.954179Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.944519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29959, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.955475Z",
     "iopub.status.busy": "2020-11-22T22:28:10.955348Z",
     "iopub.status.idle": "2020-11-22T22:28:10.976507Z",
     "shell.execute_reply": "2020-11-22T22:28:10.975901Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.955459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen Peeta Mellark Cato (Hunger Ga...</td>\n",
       "      <td>District 12, Panem Capitol, Panem Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>September 2004</td>\n",
       "      <td>Sirius Black Draco Malfoy Ron Weasley Petunia ...</td>\n",
       "      <td>Hogwarts School of Witchcraft and Wizardry Lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>May 23rd 2006</td>\n",
       "      <td>Scout Finch Atticus Finch Jem Finch Arthur Rad...</td>\n",
       "      <td>Maycomb, Alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>October 10th 2000</td>\n",
       "      <td>Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...</td>\n",
       "      <td>United Kingdom Derbyshire, England England Her...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>September 6th 2006</td>\n",
       "      <td>Edward Cullen Jacob Black Laurent Renee Bella ...</td>\n",
       "      <td>Forks, Washington Phoenix, Arizona Washington ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  Suzanne Collins         4.33    6408798.0     172554.0   \n",
       "1     J.K. Rowling         4.50    2525157.0      42734.0   \n",
       "2       Harper Lee         4.28    4527405.0      91802.0   \n",
       "3      Jane Austen         4.26    3017830.0      67811.0   \n",
       "4  Stephenie Meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  Could you survive on your own in the wild, wit...          374.0   \n",
       "1  There is a door at the end of a silent corrido...          870.0   \n",
       "2  The unforgettable novel of a childhood in a sl...          324.0   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...          279.0   \n",
       "4  About three things I was absolutely positive.F...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen Peeta Mellark Cato (Hunger Ga...   \n",
       "1       September 2004  Sirius Black Draco Malfoy Ron Weasley Petunia ...   \n",
       "2        May 23rd 2006  Scout Finch Atticus Finch Jem Finch Arthur Rad...   \n",
       "3    October 10th 2000  Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...   \n",
       "4   September 6th 2006  Edward Cullen Jacob Black Laurent Renee Bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0            District 12, Panem Capitol, Panem Panem   \n",
       "1  Hogwarts School of Witchcraft and Wizardry Lon...   \n",
       "2                                   Maycomb, Alabama   \n",
       "3  United Kingdom Derbyshire, England England Her...   \n",
       "4  Forks, Washington Phoenix, Arizona Washington ...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset cleaning [preliminary steps]\n",
    "Before actually jumping into the work itself, we want our dataframe to be clean, meaning that there are some preliminary steps we need to perform on it. First of all, missing data is something we should pay attention to. Lot's of rows are going to have missing data somewhere, and dealing with missing data it's not that nice. Notice that this will include different strategies for each of the column we will be considering (more details below). Then there is the problem with punctuation, stopwords, stems and so on so forth, so basic text data preprocessing. Let's make a brief recap:\n",
    "\n",
    "1. **Missing data**\n",
    "    - `bookTitle`: if a book is missing the title, then we can safely just remove the instance. In fact, books that are missing the title are actually missing all the informations, meaning that there is a problem with the GoodReads specific link. Also, even if a book was missing just the title, we wouldn't have a way to refer to it, thus it wouldn't be really useful considering we're building a search engine.\n",
    "    - `bookSeries`, `Authors`, `Plot`, `PublishingDate`, `Characters`, `Setting`: if a book is missing one of the above mentioned columns, we can still include the book in the data, since the search engine could for example work with just the title. Obviously, we cannot just leave the values missing, since it would be really hard to perform any operation on that. These are all text columns, therefore the best way to address the missing values prolem is to replace NaNs with empty strings.\n",
    "    - `ratingValue`, `NumberofPages`: TODO?\n",
    "2. **Text data preprocessing**\n",
    "    - Punctuation removal: this is the first step we want to perform, since it is going to make the next steps much easier (e.g., language detection will be easier if there aren't plots composed just by punctuation symbols).\n",
    "    - Language detection: before doing anything else, we want to remove the books that present the books for which the plot isn't in english.\n",
    "    - Stopwords removal (of the `Plot` column only)\n",
    "    - Stemming (of the `Plot` column only)\n",
    "    - Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title\n",
    "There are 774 books that are completely empty, and these corresponds to the ones that are missing the `bookTitle` column. If you give a look at the url, you can see that these are not given by our python script to download and parse the books, but actually from the fact that the link is broken. Also, you can see that all the books that are missing the `bookTitle` are also missing all the remaining data.\n",
    "\n",
    "This means that we can safely just remove all the rows that are missing the `bookTitle` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.978435Z",
     "iopub.status.busy": "2020-11-22T22:28:10.978266Z",
     "iopub.status.idle": "2020-11-22T22:28:10.996628Z",
     "shell.execute_reply": "2020-11-22T22:28:10.995903Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.978405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 774 instances that are missing the `bookTitle` column.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40937505\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528535\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528544\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40941582\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/5295735\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bookTitle bookSeries bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "311        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "370        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "379        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "789        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "1141       NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Plot  numberOfPages PublishingDate Characters Setting  \\\n",
       "311   NaN            NaN            NaN        NaN     NaN   \n",
       "370   NaN            NaN            NaN        NaN     NaN   \n",
       "379   NaN            NaN            NaN        NaN     NaN   \n",
       "789   NaN            NaN            NaN        NaN     NaN   \n",
       "1141  NaN            NaN            NaN        NaN     NaN   \n",
       "\n",
       "                                                   Url  \n",
       "311   https://www.goodreads.com/book/show/40937505\\r\\n  \n",
       "370   https://www.goodreads.com/book/show/30528535\\r\\n  \n",
       "379   https://www.goodreads.com/book/show/30528544\\r\\n  \n",
       "789   https://www.goodreads.com/book/show/40941582\\r\\n  \n",
       "1141   https://www.goodreads.com/book/show/5295735\\r\\n  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing = df[(df['bookTitle'].isna())].shape[0]\n",
    "print('There are {} instances that are missing the `bookTitle` column.'.format(n_missing))\n",
    "print()\n",
    "df[(df['bookTitle'].isna())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.998084Z",
     "iopub.status.busy": "2020-11-22T22:28:10.997906Z",
     "iopub.status.idle": "2020-11-22T22:28:11.010357Z",
     "shell.execute_reply": "2020-11-22T22:28:11.009755Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.998053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove empty books\n",
    "df = df[(df['bookTitle'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:11.011264Z",
     "iopub.status.busy": "2020-11-22T22:28:11.011100Z",
     "iopub.status.idle": "2020-11-22T22:28:11.029827Z",
     "shell.execute_reply": "2020-11-22T22:28:11.029237Z",
     "shell.execute_reply.started": "2020-11-22T22:28:11.011234Z"
    }
   },
   "outputs": [],
   "source": [
    "str_columns = ['bookSeries', 'bookAuthors', 'Plot', 'PublishingDate', 'Characters', 'Setting']\n",
    "\n",
    "for col in str_columns:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "There are several ways to remove punctuations, including the use of exernal libraries (like nltk). But actually the fastest way to perform punctuation removal is the use of the internal methong translate, which is programmed in C and therefore it's much faster than the other options (give a look to this [link](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string) for a nice performance analysis of the various options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:11.030547Z",
     "iopub.status.busy": "2020-11-22T22:28:11.030423Z",
     "iopub.status.idle": "2020-11-22T22:28:11.033304Z",
     "shell.execute_reply": "2020-11-22T22:28:11.032783Z",
     "shell.execute_reply.started": "2020-11-22T22:28:11.030530Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation + 'â€™'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:11.034212Z",
     "iopub.status.busy": "2020-11-22T22:28:11.034083Z",
     "iopub.status.idle": "2020-11-22T22:28:12.251882Z",
     "shell.execute_reply": "2020-11-22T22:28:12.251388Z",
     "shell.execute_reply.started": "2020-11-22T22:28:11.034195Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:11:07.055797Z",
     "iopub.status.busy": "2020-11-22T13:11:07.055640Z",
     "iopub.status.idle": "2020-11-22T13:11:07.074512Z",
     "shell.execute_reply": "2020-11-22T13:11:07.073991Z",
     "shell.execute_reply.started": "2020-11-22T13:11:07.055779Z"
    }
   },
   "source": [
    "#### Language detection\n",
    "There are four possibilities `Plot` column of a given book:\n",
    "1. It is written in english\n",
    "2. It is written in another language\n",
    "3. It is empty\n",
    "4. It contains symbols, numbers, and so on\n",
    "\n",
    "We want to keep only the ones written in english or empty, so we are just going to discard the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:12.252609Z",
     "iopub.status.busy": "2020-11-22T22:28:12.252483Z",
     "iopub.status.idle": "2020-11-22T22:28:12.255441Z",
     "shell.execute_reply": "2020-11-22T22:28:12.254855Z",
     "shell.execute_reply.started": "2020-11-22T22:28:12.252593Z"
    }
   },
   "outputs": [],
   "source": [
    "def language(s):\n",
    "    if s == '':\n",
    "        return 'empty'\n",
    "    try:\n",
    "        return detect(s)\n",
    "    except:\n",
    "        return 'symbols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:12.256337Z",
     "iopub.status.busy": "2020-11-22T22:28:12.256204Z",
     "iopub.status.idle": "2020-11-22T22:30:02.888495Z",
     "shell.execute_reply": "2020-11-22T22:30:02.888018Z",
     "shell.execute_reply.started": "2020-11-22T22:28:12.256320Z"
    }
   },
   "outputs": [],
   "source": [
    "df['plot_lang'] = df['Plot'].apply(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:02.889115Z",
     "iopub.status.busy": "2020-11-22T22:30:02.888996Z",
     "iopub.status.idle": "2020-11-22T22:30:02.908561Z",
     "shell.execute_reply": "2020-11-22T22:30:02.908093Z",
     "shell.execute_reply.started": "2020-11-22T22:30:02.889099Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[(df['plot_lang'] == 'en') | (df['plot_lang'] == 'empty')].drop(columns=['plot_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:02.909422Z",
     "iopub.status.busy": "2020-11-22T22:30:02.909238Z",
     "iopub.status.idle": "2020-11-22T22:30:02.936804Z",
     "shell.execute_reply": "2020-11-22T22:30:02.935916Z",
     "shell.execute_reply.started": "2020-11-22T22:30:02.909405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26999, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords removal\n",
    "We are not going to perform stopwords removal on all the columns, since we could remove important things (e.g., we don't want to remove anything from the names of the characters). The only column on which stopwords removal is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:02.937699Z",
     "iopub.status.busy": "2020-11-22T22:30:02.937563Z",
     "iopub.status.idle": "2020-11-22T22:30:02.952179Z",
     "shell.execute_reply": "2020-11-22T22:30:02.951778Z",
     "shell.execute_reply.started": "2020-11-22T22:30:02.937683Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(s):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:02.952927Z",
     "iopub.status.busy": "2020-11-22T22:30:02.952793Z",
     "iopub.status.idle": "2020-11-22T22:30:17.767582Z",
     "shell.execute_reply": "2020-11-22T22:30:17.767084Z",
     "shell.execute_reply.started": "2020-11-22T22:30:02.952910Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "As for the stopwords removal, the only column on which stemming is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:17.768624Z",
     "iopub.status.busy": "2020-11-22T22:30:17.768494Z",
     "iopub.status.idle": "2020-11-22T22:30:17.771717Z",
     "shell.execute_reply": "2020-11-22T22:30:17.771177Z",
     "shell.execute_reply.started": "2020-11-22T22:30:17.768607Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemming(s):\n",
    "    ps = PorterStemmer()\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([ps.stem(w) for w in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:17.772526Z",
     "iopub.status.busy": "2020-11-22T22:30:17.772389Z",
     "iopub.status.idle": "2020-11-22T22:30:58.664534Z",
     "shell.execute_reply": "2020-11-22T22:30:58.663922Z",
     "shell.execute_reply.started": "2020-11-22T22:30:17.772509Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:16:37.617866Z",
     "iopub.status.busy": "2020-11-22T15:16:37.617156Z",
     "iopub.status.idle": "2020-11-22T15:17:23.722941Z",
     "shell.execute_reply": "2020-11-22T15:17:23.722477Z",
     "shell.execute_reply.started": "2020-11-22T15:16:37.617782Z"
    }
   },
   "source": [
    "#### Lowercase\n",
    "On the other hand, we want all the string columns to be lowercase, so that our search engine won't have problems with upper/lower case differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:58.665254Z",
     "iopub.status.busy": "2020-11-22T22:30:58.665133Z",
     "iopub.status.idle": "2020-11-22T22:30:58.739900Z",
     "shell.execute_reply": "2020-11-22T22:30:58.739409Z",
     "shell.execute_reply.started": "2020-11-22T22:30:58.665239Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(lambda w: w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:30:58.740641Z",
     "iopub.status.busy": "2020-11-22T22:30:58.740491Z",
     "iopub.status.idle": "2020-11-22T22:30:58.752139Z",
     "shell.execute_reply": "2020-11-22T22:30:58.751666Z",
     "shell.execute_reply.started": "2020-11-22T22:30:58.740626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>the hunger games 1</td>\n",
       "      <td>suzanne collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>could surviv wild everi one make sure dont liv...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>september 14th 2008</td>\n",
       "      <td>katniss everdeen peeta mellark cato hunger gam...</td>\n",
       "      <td>district 12 panem capitol panem panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>harry potter 5</td>\n",
       "      <td>jk rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>there door end silent corridor and haunt harri...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>september 2004</td>\n",
       "      <td>sirius black draco malfoy ron weasley petunia ...</td>\n",
       "      <td>hogwarts school of witchcraft and wizardry lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>the unforgett novel childhood sleepi southern ...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>may 23rd 2006</td>\n",
       "      <td>scout finch atticus finch jem finch arthur rad...</td>\n",
       "      <td>maycomb alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td></td>\n",
       "      <td>jane austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>altern cover edit isbn 9780679783268sinc immed...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>october 10th 2000</td>\n",
       "      <td>mr bennet mrs bennet jane bennet elizabeth ben...</td>\n",
       "      <td>united kingdom derbyshire england england hert...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>the twilight saga 1</td>\n",
       "      <td>stephenie meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>about three thing i absolut positivefirst edwa...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>september 6th 2006</td>\n",
       "      <td>edward cullen jacob black laurent renee bella ...</td>\n",
       "      <td>forks washington phoenix arizona washington state</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games     the hunger games 1   \n",
       "1  Harry Potter and the Order of the Phoenix         harry potter 5   \n",
       "2                      To Kill a Mockingbird  to kill a mockingbird   \n",
       "3                        Pride and Prejudice                          \n",
       "4                                   Twilight    the twilight saga 1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  suzanne collins         4.33    6408798.0     172554.0   \n",
       "1       jk rowling         4.50    2525157.0      42734.0   \n",
       "2       harper lee         4.28    4527405.0      91802.0   \n",
       "3      jane austen         4.26    3017830.0      67811.0   \n",
       "4  stephenie meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  could surviv wild everi one make sure dont liv...          374.0   \n",
       "1  there door end silent corridor and haunt harri...          870.0   \n",
       "2  the unforgett novel childhood sleepi southern ...          324.0   \n",
       "3  altern cover edit isbn 9780679783268sinc immed...          279.0   \n",
       "4  about three thing i absolut positivefirst edwa...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  september 14th 2008  katniss everdeen peeta mellark cato hunger gam...   \n",
       "1       september 2004  sirius black draco malfoy ron weasley petunia ...   \n",
       "2        may 23rd 2006  scout finch atticus finch jem finch arthur rad...   \n",
       "3    october 10th 2000  mr bennet mrs bennet jane bennet elizabeth ben...   \n",
       "4   september 6th 2006  edward cullen jacob black laurent renee bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0              district 12 panem capitol panem panem   \n",
       "1  hogwarts school of witchcraft and wizardry lon...   \n",
       "2                                    maycomb alabama   \n",
       "3  united kingdom derbyshire england england hert...   \n",
       "4  forks washington phoenix arizona washington state   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:42:38.706573Z",
     "iopub.status.busy": "2020-11-22T23:42:38.706123Z",
     "iopub.status.idle": "2020-11-22T23:42:38.719978Z",
     "shell.execute_reply": "2020-11-22T23:42:38.719417Z",
     "shell.execute_reply.started": "2020-11-22T23:42:38.706519Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:42:44.418911Z",
     "iopub.status.busy": "2020-11-22T23:42:44.418626Z",
     "iopub.status.idle": "2020-11-22T23:42:44.966311Z",
     "shell.execute_reply": "2020-11-22T23:42:44.964486Z",
     "shell.execute_reply.started": "2020-11-22T23:42:44.418877Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:30:43.401230Z",
     "iopub.status.busy": "2020-11-23T13:30:43.401060Z",
     "iopub.status.idle": "2020-11-23T13:30:43.661865Z",
     "shell.execute_reply": "2020-11-23T13:30:43.661294Z",
     "shell.execute_reply.started": "2020-11-23T13:30:43.401205Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:55:06.578179Z",
     "iopub.status.busy": "2020-11-23T18:55:06.578025Z",
     "iopub.status.idle": "2020-11-23T18:55:06.581274Z",
     "shell.execute_reply": "2020-11-23T18:55:06.580783Z",
     "shell.execute_reply.started": "2020-11-23T18:55:06.578160Z"
    }
   },
   "outputs": [],
   "source": [
    "# To save and load python dictionaries\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:13:41.418476Z",
     "iopub.status.busy": "2020-11-22T23:13:41.417844Z",
     "iopub.status.idle": "2020-11-22T23:13:41.424245Z",
     "shell.execute_reply": "2020-11-22T23:13:41.423765Z",
     "shell.execute_reply.started": "2020-11-22T23:13:41.418398Z"
    }
   },
   "outputs": [],
   "source": [
    "def term_index(documents):\n",
    "    words = set()\n",
    "    for s in documents:\n",
    "        tokens = set(word_tokenize(s))\n",
    "        words.update(tokens)\n",
    "        \n",
    "    term_index = {}\n",
    "    for i, word in enumerate(words):\n",
    "        term_index[word] = i\n",
    "    return term_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:26:36.618640Z",
     "iopub.status.busy": "2020-11-22T23:26:36.618478Z",
     "iopub.status.idle": "2020-11-22T23:26:45.796953Z",
     "shell.execute_reply": "2020-11-22T23:26:45.796471Z",
     "shell.execute_reply.started": "2020-11-22T23:26:36.618621Z"
    }
   },
   "outputs": [],
   "source": [
    "term_indexes = term_index(df['Plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:15:54.837019Z",
     "iopub.status.busy": "2020-11-22T23:15:54.836831Z",
     "iopub.status.idle": "2020-11-22T23:15:54.867383Z",
     "shell.execute_reply": "2020-11-22T23:15:54.866860Z",
     "shell.execute_reply.started": "2020-11-22T23:15:54.837002Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(term_indexes, 'term_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:25:37.789240Z",
     "iopub.status.busy": "2020-11-22T23:25:37.788485Z",
     "iopub.status.idle": "2020-11-22T23:25:37.794767Z",
     "shell.execute_reply": "2020-11-22T23:25:37.794228Z",
     "shell.execute_reply.started": "2020-11-22T23:25:37.789159Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def inverted_index(documents, term_indexes):\n",
    "    inv_index = defaultdict(list)\n",
    "    for i, s in enumerate(documents):\n",
    "        tokens = set(word_tokenize(s))\n",
    "        for token in tokens:\n",
    "            token_index = term_indexes[token]\n",
    "            inv_index[token_index].append('document_{}'.format(i))\n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:26:55.480561Z",
     "iopub.status.busy": "2020-11-22T23:26:55.480374Z",
     "iopub.status.idle": "2020-11-22T23:27:06.089044Z",
     "shell.execute_reply": "2020-11-22T23:27:06.088507Z",
     "shell.execute_reply.started": "2020-11-22T23:26:55.480544Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_indexes = inverted_index(df['Plot'], term_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T23:28:26.245788Z",
     "iopub.status.busy": "2020-11-22T23:28:26.245631Z",
     "iopub.status.idle": "2020-11-22T23:28:26.787598Z",
     "shell.execute_reply": "2020-11-22T23:28:26.787087Z",
     "shell.execute_reply.started": "2020-11-22T23:28:26.245770Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(inv_indexes, 'inverted_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:55:57.907000Z",
     "iopub.status.busy": "2020-11-23T18:55:57.906341Z",
     "iopub.status.idle": "2020-11-23T18:55:57.923070Z",
     "shell.execute_reply": "2020-11-23T18:55:57.921755Z",
     "shell.execute_reply.started": "2020-11-23T18:55:57.906919Z"
    }
   },
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "    df = pd.read_csv('clean_data.csv')\n",
    "    term_indexes = load_obj('term_index')\n",
    "    inv_indexes = load_obj('inverted_index')\n",
    "    \n",
    "    \n",
    "    query_tokens = [ps.stem(w) for w in word_tokenize(query)]\n",
    "    # Create term indexes for the query\n",
    "    # notice: if one of the query element doesn't appear in the term_indexes dictionary\n",
    "    # we can safely say that the **conjunctive** query has to return nothing\n",
    "    term_indexes_tokens = []\n",
    "    for token in query_tokens:\n",
    "        try:\n",
    "            term_indexes_tokens.append(term_indexes[token])\n",
    "        except:\n",
    "            return\n",
    "    \n",
    "    query_inv_indexes = {}\n",
    "    for token_index in term_indexes_tokens:\n",
    "        query_inv_indexes[token_index] = set(inv_indexes[token_index])\n",
    "    \n",
    "    # Since it is a conjuntive query, we need to intersect the results of each query token\n",
    "    documents = set.intersection(*query_inv_indexes.values())\n",
    "    documents_id = [int(document.split('_')[1]) for document in documents]\n",
    "    documents_id.sort()\n",
    "    \n",
    "    return df[df['index'].isin(documents_id)][['bookTitle', 'Plot', 'Url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:56:00.189799Z",
     "iopub.status.busy": "2020-11-23T18:56:00.189629Z",
     "iopub.status.idle": "2020-11-23T18:56:00.766336Z",
     "shell.execute_reply": "2020-11-23T18:56:00.765637Z",
     "shell.execute_reply.started": "2020-11-23T18:56:00.189781Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5659e3dbf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecute_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'capitol love'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-12d129c56a09>\u001b[0m in \u001b[0;36mexecute_query\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mquery_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create term indexes for the query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# notice: if one of the query element doesn't appear in the term_indexes dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-12d129c56a09>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mquery_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create term indexes for the query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# notice: if one of the query element doesn't appear in the term_indexes dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ps' is not defined"
     ]
    }
   ],
   "source": [
    "execute_query('capitol love')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
