{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:22.887274Z",
     "iopub.status.busy": "2020-11-25T20:39:22.887063Z",
     "iopub.status.idle": "2020-11-25T20:39:23.669469Z",
     "shell.execute_reply": "2020-11-25T20:39:23.669035Z",
     "shell.execute_reply.started": "2020-11-25T20:39:22.887225Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import string\n",
    "import data_collector\n",
    "import parser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import heapq\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of the books\n",
    "We already have the list of books in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both dirs, bests and links parameters to create the correct directories and download the txt containing all the html links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.588151Z",
     "iopub.status.busy": "2020-11-22T22:28:10.587988Z",
     "iopub.status.idle": "2020-11-22T22:28:10.591041Z",
     "shell.execute_reply": "2020-11-22T22:28:10.590475Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.588099Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(dirs=False, bests=False, links=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Crawl books\n",
    "We already have all the htmls in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both the books and fails parameters to download all the html pages and remove the ones with broken pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.593990Z",
     "iopub.status.busy": "2020-11-22T22:28:10.593855Z",
     "iopub.status.idle": "2020-11-22T22:28:10.634453Z",
     "shell.execute_reply": "2020-11-22T22:28:10.633377Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.593972Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(books=False, fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Parse downloaded pages\n",
    "Set to `True` the create parameter to parse the downloaded html pages and create the tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.635794Z",
     "iopub.status.busy": "2020-11-22T22:28:10.635569Z",
     "iopub.status.idle": "2020-11-22T22:28:10.648884Z",
     "shell.execute_reply": "2020-11-22T22:28:10.648186Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.635759Z"
    }
   },
   "outputs": [],
   "source": [
    "parser.create_tsv(create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:27.523443Z",
     "iopub.status.busy": "2020-11-25T20:39:27.523122Z",
     "iopub.status.idle": "2020-11-25T20:39:27.804814Z",
     "shell.execute_reply": "2020-11-25T20:39:27.804332Z",
     "shell.execute_reply.started": "2020-11-25T20:39:27.523404Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('parsed_books.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:06:52.624394Z",
     "iopub.status.busy": "2020-11-25T20:06:52.624225Z",
     "iopub.status.idle": "2020-11-25T20:06:52.628135Z",
     "shell.execute_reply": "2020-11-25T20:06:52.627687Z",
     "shell.execute_reply.started": "2020-11-25T20:06:52.624375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29959, 12)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:06:52.629289Z",
     "iopub.status.busy": "2020-11-25T20:06:52.629082Z",
     "iopub.status.idle": "2020-11-25T20:06:52.649296Z",
     "shell.execute_reply": "2020-11-25T20:06:52.648710Z",
     "shell.execute_reply.started": "2020-11-25T20:06:52.629270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen Peeta Mellark Cato (Hunger Ga...</td>\n",
       "      <td>District 12, Panem Capitol, Panem Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>September 2004</td>\n",
       "      <td>Sirius Black Draco Malfoy Ron Weasley Petunia ...</td>\n",
       "      <td>Hogwarts School of Witchcraft and Wizardry Lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>May 23rd 2006</td>\n",
       "      <td>Scout Finch Atticus Finch Jem Finch Arthur Rad...</td>\n",
       "      <td>Maycomb, Alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>October 10th 2000</td>\n",
       "      <td>Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...</td>\n",
       "      <td>United Kingdom Derbyshire, England England Her...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>September 6th 2006</td>\n",
       "      <td>Edward Cullen Jacob Black Laurent Renee Bella ...</td>\n",
       "      <td>Forks, Washington Phoenix, Arizona Washington ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  Suzanne Collins         4.33    6408798.0     172554.0   \n",
       "1     J.K. Rowling         4.50    2525157.0      42734.0   \n",
       "2       Harper Lee         4.28    4527405.0      91802.0   \n",
       "3      Jane Austen         4.26    3017830.0      67811.0   \n",
       "4  Stephenie Meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  Could you survive on your own in the wild, wit...          374.0   \n",
       "1  There is a door at the end of a silent corrido...          870.0   \n",
       "2  The unforgettable novel of a childhood in a sl...          324.0   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...          279.0   \n",
       "4  About three things I was absolutely positive.F...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen Peeta Mellark Cato (Hunger Ga...   \n",
       "1       September 2004  Sirius Black Draco Malfoy Ron Weasley Petunia ...   \n",
       "2        May 23rd 2006  Scout Finch Atticus Finch Jem Finch Arthur Rad...   \n",
       "3    October 10th 2000  Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...   \n",
       "4   September 6th 2006  Edward Cullen Jacob Black Laurent Renee Bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0            District 12, Panem Capitol, Panem Panem   \n",
       "1  Hogwarts School of Witchcraft and Wizardry Lon...   \n",
       "2                                   Maycomb, Alabama   \n",
       "3  United Kingdom Derbyshire, England England Her...   \n",
       "4  Forks, Washington Phoenix, Arizona Washington ...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset cleaning [preliminary steps]\n",
    "Before actually jumping into the work itself, we want our dataframe to be clean, meaning that there are some preliminary steps we need to perform on it. First of all, missing data is something we should pay attention to. Lot's of rows are going to have missing data somewhere, and dealing with missing data it's not that nice. Notice that this will include different strategies for each of the column we will be considering (more details below). Then there is the problem with punctuation, stopwords, stems and so on so forth, so basic text data preprocessing. Let's make a brief recap:\n",
    "\n",
    "1. **Missing data**\n",
    "    - `bookTitle`: if a book is missing the title, then we can safely just remove the instance. In fact, books that are missing the title are actually missing all the informations, meaning that there is a problem with the GoodReads specific link. Also, even if a book was missing just the title, we wouldn't have a way to refer to it, thus it wouldn't be really useful considering we're building a search engine.\n",
    "    - `bookSeries`, `Authors`, `Plot`, `PublishingDate`, `Characters`, `Setting`: if a book is missing one of the above mentioned columns, we can still include the book in the data, since the search engine could for example work with just the title. Obviously, we cannot just leave the values missing, since it would be really hard to perform any operation on that. These are all text columns, therefore the best way to address the missing values prolem is to replace NaNs with empty strings.\n",
    "    - `ratingValue`, `NumberofPages`: TODO?\n",
    "2. **Text data preprocessing**\n",
    "    - Punctuation removal: this is the first step we want to perform, since it is going to make the next steps much easier (e.g., language detection will be easier if there aren't plots composed just by punctuation symbols).\n",
    "    - Language detection: before doing anything else, we want to remove the books that present the books for which the plot isn't in english.\n",
    "    - Stopwords removal (of the `Plot` column only)\n",
    "    - Stemming (of the `Plot` column only)\n",
    "    - Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title\n",
    "There are 774 books that are completely empty, and these corresponds to the ones that are missing the `bookTitle` column. If you give a look at the url, you can see that these are not given by our python script to download and parse the books, but actually from the fact that the link is broken. Also, you can see that all the books that are missing the `bookTitle` are also missing all the remaining data.\n",
    "\n",
    "This means that we can safely just remove all the rows that are missing the `bookTitle` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:31.908925Z",
     "iopub.status.busy": "2020-11-25T20:39:31.908682Z",
     "iopub.status.idle": "2020-11-25T20:39:31.932318Z",
     "shell.execute_reply": "2020-11-25T20:39:31.931804Z",
     "shell.execute_reply.started": "2020-11-25T20:39:31.908897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 774 instances that are missing the `bookTitle` column.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40937505\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528535\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528544\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40941582\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/5295735\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bookTitle bookSeries bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "311        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "370        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "379        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "789        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "1141       NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Plot  numberOfPages PublishingDate Characters Setting  \\\n",
       "311   NaN            NaN            NaN        NaN     NaN   \n",
       "370   NaN            NaN            NaN        NaN     NaN   \n",
       "379   NaN            NaN            NaN        NaN     NaN   \n",
       "789   NaN            NaN            NaN        NaN     NaN   \n",
       "1141  NaN            NaN            NaN        NaN     NaN   \n",
       "\n",
       "                                                   Url  \n",
       "311   https://www.goodreads.com/book/show/40937505\\r\\n  \n",
       "370   https://www.goodreads.com/book/show/30528535\\r\\n  \n",
       "379   https://www.goodreads.com/book/show/30528544\\r\\n  \n",
       "789   https://www.goodreads.com/book/show/40941582\\r\\n  \n",
       "1141   https://www.goodreads.com/book/show/5295735\\r\\n  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing = df[(df['bookTitle'].isna())].shape[0]\n",
    "print('There are {} instances that are missing the `bookTitle` column.'.format(n_missing))\n",
    "print()\n",
    "df[(df['bookTitle'].isna())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:32.072804Z",
     "iopub.status.busy": "2020-11-25T20:39:32.072642Z",
     "iopub.status.idle": "2020-11-25T20:39:32.081468Z",
     "shell.execute_reply": "2020-11-25T20:39:32.080946Z",
     "shell.execute_reply.started": "2020-11-25T20:39:32.072786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove empty books\n",
    "df = df[(df['bookTitle'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:39:33.717347Z",
     "iopub.status.busy": "2020-11-25T20:39:33.716718Z",
     "iopub.status.idle": "2020-11-25T20:39:33.735160Z",
     "shell.execute_reply": "2020-11-25T20:39:33.734668Z",
     "shell.execute_reply.started": "2020-11-25T20:39:33.717269Z"
    }
   },
   "outputs": [],
   "source": [
    "str_columns = ['bookSeries', 'bookAuthors', 'Plot', 'PublishingDate', 'Characters', 'Setting']\n",
    "\n",
    "for col in str_columns:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "There are several ways to remove punctuations, including the use of exernal libraries (like nltk). But actually the fastest way to perform punctuation removal is the use of the internal methong translate, which is programmed in C and therefore it's much faster than the other options (give a look to this [link](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string) for a nice performance analysis of the various options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:40:32.758968Z",
     "iopub.status.busy": "2020-11-25T20:40:32.758782Z",
     "iopub.status.idle": "2020-11-25T20:40:32.761318Z",
     "shell.execute_reply": "2020-11-25T20:40:32.760822Z",
     "shell.execute_reply.started": "2020-11-25T20:40:32.758940Z"
    }
   },
   "outputs": [],
   "source": [
    "s = 'This is a test string, asdw.ith lots of: punctuations; in it?!.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:41:20.710810Z",
     "iopub.status.busy": "2020-11-25T20:41:20.710147Z",
     "iopub.status.idle": "2020-11-25T20:41:20.716628Z",
     "shell.execute_reply": "2020-11-25T20:41:20.715966Z",
     "shell.execute_reply.started": "2020-11-25T20:41:20.710728Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation + '’—'))\n",
    "\n",
    "def remove_punctuation_(s):\n",
    "    return re.sub(\"[^\\w\\s]\", \" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:07:41.092774Z",
     "iopub.status.busy": "2020-11-25T20:07:41.092547Z",
     "iopub.status.idle": "2020-11-25T20:07:41.844175Z",
     "shell.execute_reply": "2020-11-25T20:07:41.843679Z",
     "shell.execute_reply.started": "2020-11-25T20:07:41.092746Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    if col == 'Plot':\n",
    "        df[col] = df[col].apply(remove_punctuation_)\n",
    "    else:\n",
    "        df[col] = df[col].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:11:07.055797Z",
     "iopub.status.busy": "2020-11-22T13:11:07.055640Z",
     "iopub.status.idle": "2020-11-22T13:11:07.074512Z",
     "shell.execute_reply": "2020-11-22T13:11:07.073991Z",
     "shell.execute_reply.started": "2020-11-22T13:11:07.055779Z"
    }
   },
   "source": [
    "#### Language detection\n",
    "There are four possibilities `Plot` column of a given book:\n",
    "1. It is written in english\n",
    "2. It is written in another language\n",
    "3. It is empty\n",
    "4. It contains symbols, numbers, and so on\n",
    "\n",
    "We want to keep only the ones written in english or empty, so we are just going to discard the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:07:46.940690Z",
     "iopub.status.busy": "2020-11-25T20:07:46.940514Z",
     "iopub.status.idle": "2020-11-25T20:07:46.943455Z",
     "shell.execute_reply": "2020-11-25T20:07:46.942954Z",
     "shell.execute_reply.started": "2020-11-25T20:07:46.940671Z"
    }
   },
   "outputs": [],
   "source": [
    "def language(s):\n",
    "    if s == '':\n",
    "        return 'empty'\n",
    "    try:\n",
    "        return detect(s)\n",
    "    except:\n",
    "        return 'symbols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:07:47.025425Z",
     "iopub.status.busy": "2020-11-25T20:07:47.025241Z",
     "iopub.status.idle": "2020-11-25T20:09:53.400501Z",
     "shell.execute_reply": "2020-11-25T20:09:53.400043Z",
     "shell.execute_reply.started": "2020-11-25T20:07:47.025405Z"
    }
   },
   "outputs": [],
   "source": [
    "df['plot_lang'] = df['Plot'].apply(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.401361Z",
     "iopub.status.busy": "2020-11-25T20:09:53.401215Z",
     "iopub.status.idle": "2020-11-25T20:09:53.420128Z",
     "shell.execute_reply": "2020-11-25T20:09:53.419712Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.401343Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['plot_lang'] == 'en'].drop(columns=['plot_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.421196Z",
     "iopub.status.busy": "2020-11-25T20:09:53.421061Z",
     "iopub.status.idle": "2020-11-25T20:09:53.446046Z",
     "shell.execute_reply": "2020-11-25T20:09:53.445548Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.421178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26126, 12)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords removal\n",
    "We are not going to perform stopwords removal on all the columns, since we could remove important things (e.g., we don't want to remove anything from the names of the characters). The only column on which stopwords removal is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.447014Z",
     "iopub.status.busy": "2020-11-25T20:09:53.446856Z",
     "iopub.status.idle": "2020-11-25T20:09:53.454281Z",
     "shell.execute_reply": "2020-11-25T20:09:53.453818Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.446996Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(s):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:09:53.455059Z",
     "iopub.status.busy": "2020-11-25T20:09:53.454924Z",
     "iopub.status.idle": "2020-11-25T20:10:10.937813Z",
     "shell.execute_reply": "2020-11-25T20:10:10.937380Z",
     "shell.execute_reply.started": "2020-11-25T20:09:53.455040Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "As for the stopwords removal, the only column on which stemming is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:10:10.938712Z",
     "iopub.status.busy": "2020-11-25T20:10:10.938585Z",
     "iopub.status.idle": "2020-11-25T20:10:10.944140Z",
     "shell.execute_reply": "2020-11-25T20:10:10.943681Z",
     "shell.execute_reply.started": "2020-11-25T20:10:10.938695Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemming(s):\n",
    "    ps = PorterStemmer()\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([ps.stem(w) for w in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:10:10.944945Z",
     "iopub.status.busy": "2020-11-25T20:10:10.944812Z",
     "iopub.status.idle": "2020-11-25T20:11:44.967705Z",
     "shell.execute_reply": "2020-11-25T20:11:44.967208Z",
     "shell.execute_reply.started": "2020-11-25T20:10:10.944927Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(stemming)\n",
    "df['Plot'] = df['Plot'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:16:37.617866Z",
     "iopub.status.busy": "2020-11-22T15:16:37.617156Z",
     "iopub.status.idle": "2020-11-22T15:17:23.722941Z",
     "shell.execute_reply": "2020-11-22T15:17:23.722477Z",
     "shell.execute_reply.started": "2020-11-22T15:16:37.617782Z"
    }
   },
   "source": [
    "#### Lowercase\n",
    "On the other hand, we want all the string columns to be lowercase, so that our search engine won't have problems with upper/lower case differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:44.968852Z",
     "iopub.status.busy": "2020-11-25T20:11:44.968725Z",
     "iopub.status.idle": "2020-11-25T20:11:45.017540Z",
     "shell.execute_reply": "2020-11-25T20:11:45.017057Z",
     "shell.execute_reply.started": "2020-11-25T20:11:44.968835Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(lambda w: w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:45.018349Z",
     "iopub.status.busy": "2020-11-25T20:11:45.018215Z",
     "iopub.status.idle": "2020-11-25T20:11:45.043678Z",
     "shell.execute_reply": "2020-11-25T20:11:45.042964Z",
     "shell.execute_reply.started": "2020-11-25T20:11:45.018331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>the hunger games 1</td>\n",
       "      <td>suzanne collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>september 14th 2008</td>\n",
       "      <td>katniss everdeen peeta mellark cato hunger gam...</td>\n",
       "      <td>district 12 panem capitol panem panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>harry potter 5</td>\n",
       "      <td>jk rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>there door end silent corridor and haunt harri...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>september 2004</td>\n",
       "      <td>sirius black draco malfoy ron weasley petunia ...</td>\n",
       "      <td>hogwarts school of witchcraft and wizardry lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>the unforgett novel childhood sleepi southern ...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>may 23rd 2006</td>\n",
       "      <td>scout finch atticus finch jem finch arthur rad...</td>\n",
       "      <td>maycomb alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td></td>\n",
       "      <td>jane austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>altern cover edit isbn 9780679783268sinc immed...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>october 10th 2000</td>\n",
       "      <td>mr bennet mrs bennet jane bennet elizabeth ben...</td>\n",
       "      <td>united kingdom derbyshire england england hert...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>the twilight saga 1</td>\n",
       "      <td>stephenie meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>about three thing i absolut posit first edward...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>september 6th 2006</td>\n",
       "      <td>edward cullen jacob black laurent renee bella ...</td>\n",
       "      <td>forks washington phoenix arizona washington state</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games     the hunger games 1   \n",
       "1  Harry Potter and the Order of the Phoenix         harry potter 5   \n",
       "2                      To Kill a Mockingbird  to kill a mockingbird   \n",
       "3                        Pride and Prejudice                          \n",
       "4                                   Twilight    the twilight saga 1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  suzanne collins         4.33    6408798.0     172554.0   \n",
       "1       jk rowling         4.50    2525157.0      42734.0   \n",
       "2       harper lee         4.28    4527405.0      91802.0   \n",
       "3      jane austen         4.26    3017830.0      67811.0   \n",
       "4  stephenie meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  could surviv wild everi one make sure live see...          374.0   \n",
       "1  there door end silent corridor and haunt harri...          870.0   \n",
       "2  the unforgett novel childhood sleepi southern ...          324.0   \n",
       "3  altern cover edit isbn 9780679783268sinc immed...          279.0   \n",
       "4  about three thing i absolut posit first edward...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  september 14th 2008  katniss everdeen peeta mellark cato hunger gam...   \n",
       "1       september 2004  sirius black draco malfoy ron weasley petunia ...   \n",
       "2        may 23rd 2006  scout finch atticus finch jem finch arthur rad...   \n",
       "3    october 10th 2000  mr bennet mrs bennet jane bennet elizabeth ben...   \n",
       "4   september 6th 2006  edward cullen jacob black laurent renee bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0              district 12 panem capitol panem panem   \n",
       "1  hogwarts school of witchcraft and wizardry lon...   \n",
       "2                                    maycomb alabama   \n",
       "3  united kingdom derbyshire england england hert...   \n",
       "4  forks washington phoenix arizona washington state   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:45.045056Z",
     "iopub.status.busy": "2020-11-25T20:11:45.044805Z",
     "iopub.status.idle": "2020-11-25T20:11:45.058014Z",
     "shell.execute_reply": "2020-11-25T20:11:45.057449Z",
     "shell.execute_reply.started": "2020-11-25T20:11:45.045024Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:11:45.058683Z",
     "iopub.status.busy": "2020-11-25T20:11:45.058557Z",
     "iopub.status.idle": "2020-11-25T20:11:45.579037Z",
     "shell.execute_reply": "2020-11-25T20:11:45.578498Z",
     "shell.execute_reply.started": "2020-11-25T20:11:45.058666Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:19.225073Z",
     "iopub.status.busy": "2020-11-25T20:42:19.224886Z",
     "iopub.status.idle": "2020-11-25T20:42:19.420792Z",
     "shell.execute_reply": "2020-11-25T20:42:19.420308Z",
     "shell.execute_reply.started": "2020-11-25T20:42:19.225056Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:20.057723Z",
     "iopub.status.busy": "2020-11-25T20:42:20.057373Z",
     "iopub.status.idle": "2020-11-25T20:42:20.062836Z",
     "shell.execute_reply": "2020-11-25T20:42:20.061995Z",
     "shell.execute_reply.started": "2020-11-25T20:42:20.057687Z"
    }
   },
   "outputs": [],
   "source": [
    "# To save and load python dictionaries\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:20.693224Z",
     "iopub.status.busy": "2020-11-25T20:42:20.692918Z",
     "iopub.status.idle": "2020-11-25T20:42:20.698372Z",
     "shell.execute_reply": "2020-11-25T20:42:20.697574Z",
     "shell.execute_reply.started": "2020-11-25T20:42:20.693189Z"
    }
   },
   "outputs": [],
   "source": [
    "def term_index(documents):\n",
    "    words = set()\n",
    "    for s in documents:\n",
    "        try:\n",
    "            tokens = set(word_tokenize(s))\n",
    "            words.update(tokens)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    term_index = {}\n",
    "    for i, word in enumerate(words):\n",
    "        term_index[word] = i\n",
    "    return term_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:24.832442Z",
     "iopub.status.busy": "2020-11-25T20:42:24.831795Z",
     "iopub.status.idle": "2020-11-25T20:42:33.100048Z",
     "shell.execute_reply": "2020-11-25T20:42:33.099569Z",
     "shell.execute_reply.started": "2020-11-25T20:42:24.832362Z"
    }
   },
   "outputs": [],
   "source": [
    "term_indexes = term_index(df['Plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:33.690111Z",
     "iopub.status.busy": "2020-11-25T20:42:33.689772Z",
     "iopub.status.idle": "2020-11-25T20:42:33.712233Z",
     "shell.execute_reply": "2020-11-25T20:42:33.711352Z",
     "shell.execute_reply.started": "2020-11-25T20:42:33.690071Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(term_indexes, 'term_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:35.001167Z",
     "iopub.status.busy": "2020-11-25T20:42:35.000591Z",
     "iopub.status.idle": "2020-11-25T20:42:35.011853Z",
     "shell.execute_reply": "2020-11-25T20:42:35.010033Z",
     "shell.execute_reply.started": "2020-11-25T20:42:35.001096Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverted_index(documents, term_indexes):\n",
    "    inv_index = defaultdict(list)\n",
    "    for i, s in enumerate(documents):\n",
    "        try:\n",
    "            tokens = set(word_tokenize(s))\n",
    "            for token in tokens:\n",
    "                token_index = term_indexes[token]\n",
    "                inv_index[token_index].append(i)\n",
    "        except:\n",
    "            continue\n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:35.468466Z",
     "iopub.status.busy": "2020-11-25T20:42:35.468107Z",
     "iopub.status.idle": "2020-11-25T20:42:45.479227Z",
     "shell.execute_reply": "2020-11-25T20:42:45.477769Z",
     "shell.execute_reply.started": "2020-11-25T20:42:35.468423Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_indexes = inverted_index(df['Plot'], term_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:45.481584Z",
     "iopub.status.busy": "2020-11-25T20:42:45.481072Z",
     "iopub.status.idle": "2020-11-25T20:42:45.571401Z",
     "shell.execute_reply": "2020-11-25T20:42:45.570771Z",
     "shell.execute_reply.started": "2020-11-25T20:42:45.481475Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(inv_indexes, 'inverted_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:47.000147Z",
     "iopub.status.busy": "2020-11-25T20:42:46.999541Z",
     "iopub.status.idle": "2020-11-25T20:42:47.008201Z",
     "shell.execute_reply": "2020-11-25T20:42:47.007539Z",
     "shell.execute_reply.started": "2020-11-25T20:42:47.000073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write it as a classs\n",
    "\n",
    "class SimpleSearchEngine:\n",
    "    def __init__(self, df, term_indexes, inv_indexes):\n",
    "        self.df = df\n",
    "        self.term_indexes = term_indexes\n",
    "        self.inv_indexes = inv_indexes\n",
    "        \n",
    "    def execute_query(self, query):\n",
    "        # Since we performed stemming on the plot column of the dataframe, we need to\n",
    "        # perform stemming also on the query. Otherwise, our results wouldn't be accurate\n",
    "        ps = PorterStemmer()\n",
    "        query_tokens = set([ps.stem(w) for w in word_tokenize(query)])\n",
    "\n",
    "        # Create term indexes for the query\n",
    "        # notice: if one of the query element doesn't appear in the term_indexes dictionary\n",
    "        # we can safely say that the **conjunctive** query has to return nothing\n",
    "        term_indexes_tokens = []\n",
    "        for token in query_tokens:\n",
    "            if token in self.term_indexes.keys():\n",
    "                term_indexes_tokens.append(self.term_indexes[token])\n",
    "            else:\n",
    "                print('No results')\n",
    "                return pd.DataFrame(columns=['bookTitle', 'Plot', 'Url'])\n",
    "\n",
    "        query_inv_indexes = {}\n",
    "        for token_index in term_indexes_tokens:\n",
    "            query_inv_indexes[token_index] = set(self.inv_indexes[token_index])\n",
    "\n",
    "        # Since it is a conjuntive query, we need to intersect the results of each query token\n",
    "        documents_id = sorted(set.intersection(*query_inv_indexes.values()))\n",
    "\n",
    "        return self.df[self.df['index'].isin(documents_id)][['bookTitle', 'Plot', 'Url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:50.575291Z",
     "iopub.status.busy": "2020-11-25T20:42:50.574663Z",
     "iopub.status.idle": "2020-11-25T20:42:50.584157Z",
     "shell.execute_reply": "2020-11-25T20:42:50.581759Z",
     "shell.execute_reply.started": "2020-11-25T20:42:50.575214Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_se = SimpleSearchEngine(df, term_indexes, inv_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:42:56.245357Z",
     "iopub.status.busy": "2020-11-25T20:42:56.245170Z",
     "iopub.status.idle": "2020-11-25T20:42:56.255363Z",
     "shell.execute_reply": "2020-11-25T20:42:56.254846Z",
     "shell.execute_reply.started": "2020-11-25T20:42:56.245339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>spark are ignit flame are spread and the capit...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6148028-ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book ground break hunger game trilog...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Legend</td>\n",
       "      <td>what western unit state home republ nation per...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9275658-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>The Magus</td>\n",
       "      <td>thi dare literari thriller rich erot suspen on...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16286.The_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25067</th>\n",
       "      <td>The Manhattan Hunt Club</td>\n",
       "      <td>in manhattan hunt club john saul plumb depth m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6553.The_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25531</th>\n",
       "      <td>Love's Forbidden Flower</td>\n",
       "      <td>plea note thi new adult romanc novel involv tw...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16189423-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25806</th>\n",
       "      <td>The Southpaw</td>\n",
       "      <td>the southpaw stori come age america way baseb ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/413736.The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25827</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26064</th>\n",
       "      <td>Indian Hill</td>\n",
       "      <td>a michael talbot adventur thi first stori ordi...</td>\n",
       "      <td>https://www.goodreads.com/book/show/13305176-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bookTitle  \\\n",
       "0             The Hunger Games   \n",
       "221              Catching Fire   \n",
       "319                 Mockingjay   \n",
       "337                     Legend   \n",
       "652                  The Magus   \n",
       "...                        ...   \n",
       "25067  The Manhattan Hunt Club   \n",
       "25531  Love's Forbidden Flower   \n",
       "25806             The Southpaw   \n",
       "25827              Devil's Own   \n",
       "26064              Indian Hill   \n",
       "\n",
       "                                                    Plot  \\\n",
       "0      could surviv wild everi one make sure live see...   \n",
       "221    spark are ignit flame are spread and the capit...   \n",
       "319    the final book ground break hunger game trilog...   \n",
       "337    what western unit state home republ nation per...   \n",
       "652    thi dare literari thriller rich erot suspen on...   \n",
       "...                                                  ...   \n",
       "25067  in manhattan hunt club john saul plumb depth m...   \n",
       "25531  plea note thi new adult romanc novel involv tw...   \n",
       "25806  the southpaw stori come age america way baseb ...   \n",
       "25827  after surviv slaveri aiden macalpin noth thoug...   \n",
       "26064  a michael talbot adventur thi first stori ordi...   \n",
       "\n",
       "                                                     Url  \n",
       "0      https://www.goodreads.com/book/show/2767052-th...  \n",
       "221    https://www.goodreads.com/book/show/6148028-ca...  \n",
       "319    https://www.goodreads.com/book/show/7260188-mo...  \n",
       "337    https://www.goodreads.com/book/show/9275658-le...  \n",
       "652    https://www.goodreads.com/book/show/16286.The_...  \n",
       "...                                                  ...  \n",
       "25067  https://www.goodreads.com/book/show/6553.The_M...  \n",
       "25531  https://www.goodreads.com/book/show/16189423-l...  \n",
       "25806  https://www.goodreads.com/book/show/413736.The...  \n",
       "25827  https://www.goodreads.com/book/show/8705483-de...  \n",
       "26064  https://www.goodreads.com/book/show/13305176-i...  \n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_se.execute_query('survival games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:43:07.106149Z",
     "iopub.status.busy": "2020-11-25T20:43:07.105984Z",
     "iopub.status.idle": "2020-11-25T20:43:07.110714Z",
     "shell.execute_reply": "2020-11-25T20:43:07.110248Z",
     "shell.execute_reply.started": "2020-11-25T20:43:07.106130Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_inv_indexes(documents, term_indexes, inv_indexes, corpus=df):\n",
    "    tfidf_indexes = defaultdict(dict)\n",
    "    for doc_id, s in enumerate(documents):\n",
    "        try:\n",
    "            tokens = word_tokenize(s)\n",
    "            tokens_set = set(tokens)\n",
    "            n_tokens = len(tokens)\n",
    "            norm = 0\n",
    "            for token in tokens_set:\n",
    "                token_index = term_indexes[token]\n",
    "                # tf = n_times token appears in the document over the number of words of the document\n",
    "                tf = s.count(token) / n_tokens\n",
    "                # idf = log of the number of documents in the corpus over the number of documents in which the token appears\n",
    "                idf = math.log10(len(corpus) / (len(inv_indexes[token_index])))\n",
    "                tf_idf = tf * idf\n",
    "                # we just computed the tfidf for the a particular token, for the document we're considering\n",
    "                tfidf_indexes[token_index][doc_id] = tf * idf\n",
    "                \n",
    "                # Store also the norm for the document we're considering\n",
    "                # which is sqrt of the sum of the squares\n",
    "                norm += tf_idf ** 2\n",
    "                \n",
    "            # apply sqrt\n",
    "            norm = np.sqrt(norm)\n",
    "            # Normalize each document tfidf\n",
    "            for token in tokens_set:\n",
    "                token_index = term_indexes[token]\n",
    "                tfidf_indexes[token_index][doc_id] /= norm\n",
    "        except:\n",
    "            continue\n",
    "    return tfidf_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:43:18.263570Z",
     "iopub.status.busy": "2020-11-25T20:43:18.263379Z",
     "iopub.status.idle": "2020-11-25T20:43:32.899987Z",
     "shell.execute_reply": "2020-11-25T20:43:32.899464Z",
     "shell.execute_reply.started": "2020-11-25T20:43:18.263552Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_indexes = tfidf_inv_indexes(df['Plot'], term_indexes, inv_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:43:32.900823Z",
     "iopub.status.busy": "2020-11-25T20:43:32.900701Z",
     "iopub.status.idle": "2020-11-25T20:43:38.339828Z",
     "shell.execute_reply": "2020-11-25T20:43:38.338955Z",
     "shell.execute_reply.started": "2020-11-25T20:43:32.900807Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(tfidf_indexes, 'tfidf_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:52:15.072420Z",
     "iopub.status.busy": "2020-11-25T20:52:15.071754Z",
     "iopub.status.idle": "2020-11-25T20:52:15.080351Z",
     "shell.execute_reply": "2020-11-25T20:52:15.079842Z",
     "shell.execute_reply.started": "2020-11-25T20:52:15.072338Z"
    }
   },
   "outputs": [],
   "source": [
    "class TfidfSearchEngine:\n",
    "    def __init__(self, df, term_indexes, inv_indexes, tfidf_indexes, simple_se):\n",
    "        self.df = df\n",
    "        self.term_indexes = term_indexes\n",
    "        self.inv_indexes = inv_indexes\n",
    "        self.tfidf_indexes = tfidf_indexes\n",
    "        self.simple_se = simple_se\n",
    "        \n",
    "    def execute_query(self, query, k):\n",
    "        # First stem the query\n",
    "        ps = PorterStemmer()\n",
    "        query_tokens = set([ps.stem(w) for w in word_tokenize(query)])\n",
    "        \n",
    "        # Extract the token indexes from the vocabulary\n",
    "        tokens_ids = []\n",
    "        for token in query_tokens:\n",
    "            try:\n",
    "                tokens_ids.append(self.term_indexes[token])\n",
    "            except:\n",
    "                return\n",
    "        \n",
    "        # Compute the simple conjunctive query to get the books in which the query appears\n",
    "        conj_query = self.simple_se.execute_query(query)\n",
    "        \n",
    "        # Extract the documents id for these books\n",
    "        conj_query_ids = conj_query.index\n",
    "\n",
    "        # Compute the similiarity\n",
    "        scores = np.array([])\n",
    "        for doc in conj_query_ids:\n",
    "            tfidf = 0\n",
    "            for token_id in tokens_ids:\n",
    "                tfidf += self.tfidf_indexes[token_id][doc]\n",
    "            \n",
    "            scores = np.append(scores, tfidf)\n",
    "        \n",
    "        # Not really necessary since we do it for each book\n",
    "        # scores /= np.sqrt(len(query.split()))\n",
    "        \n",
    "        conj_query['Similarity'] = scores\n",
    "\n",
    "        # Use heaps to extract top k rows\n",
    "        conj_query_list = conj_query.values.tolist()\n",
    "        heapq.heapify(conj_query_list)\n",
    "        max_k = heapq.nlargest(k, conj_query_list, key = lambda t: t[3])\n",
    "        \n",
    "        # Convert back to dataframe to show it\n",
    "        max_k_df = pd.DataFrame(data=max_k, columns=['bookTitle', 'Plot', 'Url', 'Similarity'])\n",
    "\n",
    "        return max_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:45:54.651010Z",
     "iopub.status.busy": "2020-11-25T20:45:54.650707Z",
     "iopub.status.idle": "2020-11-25T20:45:54.654913Z",
     "shell.execute_reply": "2020-11-25T20:45:54.654079Z",
     "shell.execute_reply.started": "2020-11-25T20:45:54.650974Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_se = TfidfSearchEngine(df, term_indexes, inv_indexes, tfidf_indexes, simple_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T20:45:54.735100Z",
     "iopub.status.busy": "2020-11-25T20:45:54.734932Z",
     "iopub.status.idle": "2020-11-25T20:45:54.748050Z",
     "shell.execute_reply": "2020-11-25T20:45:54.747518Z",
     "shell.execute_reply.started": "2020-11-25T20:45:54.735081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Warden</td>\n",
       "      <td>alic led normal life she wake find trap sick g...</td>\n",
       "      <td>https://www.goodreads.com/book/show/33655366-t...</td>\n",
       "      <td>0.495827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "      <td>0.392048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Quillan Games</td>\n",
       "      <td>let the game begin quillan territori verg dest...</td>\n",
       "      <td>https://www.goodreads.com/book/show/215540.The...</td>\n",
       "      <td>0.353052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure live see...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "      <td>0.318387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Truth</td>\n",
       "      <td>from new york time usa today bestsel author al...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16070018-t...</td>\n",
       "      <td>0.247382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Amber Room</td>\n",
       "      <td>the amber room one greatest treasur ever made ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/5369.The_A...</td>\n",
       "      <td>0.024363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Hideaway</td>\n",
       "      <td>devil s night return hide place chase game bac...</td>\n",
       "      <td>https://www.goodreads.com/book/show/29082755-h...</td>\n",
       "      <td>0.024275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Fire &amp; Blood</td>\n",
       "      <td>with fire furi fan come expect intern bestsel ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/39943621-f...</td>\n",
       "      <td>0.022846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Dark Stranger: The Dream</td>\n",
       "      <td>smart spici the children the god paranorm roma...</td>\n",
       "      <td>https://www.goodreads.com/book/show/26005898-d...</td>\n",
       "      <td>0.018306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Tolomay's World and The Pool of Light</td>\n",
       "      <td>so much more than a romanc fantasi if enjoy hu...</td>\n",
       "      <td>https://www.goodreads.com/book/show/17379067-t...</td>\n",
       "      <td>0.011589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 bookTitle  \\\n",
       "0                               The Warden   \n",
       "1                              Devil's Own   \n",
       "2                        The Quillan Games   \n",
       "3                         The Hunger Games   \n",
       "4                                    Truth   \n",
       "..                                     ...   \n",
       "108                         The Amber Room   \n",
       "109                               Hideaway   \n",
       "110                           Fire & Blood   \n",
       "111               Dark Stranger: The Dream   \n",
       "112  Tolomay's World and The Pool of Light   \n",
       "\n",
       "                                                  Plot  \\\n",
       "0    alic led normal life she wake find trap sick g...   \n",
       "1    after surviv slaveri aiden macalpin noth thoug...   \n",
       "2    let the game begin quillan territori verg dest...   \n",
       "3    could surviv wild everi one make sure live see...   \n",
       "4    from new york time usa today bestsel author al...   \n",
       "..                                                 ...   \n",
       "108  the amber room one greatest treasur ever made ...   \n",
       "109  devil s night return hide place chase game bac...   \n",
       "110  with fire furi fan come expect intern bestsel ...   \n",
       "111  smart spici the children the god paranorm roma...   \n",
       "112  so much more than a romanc fantasi if enjoy hu...   \n",
       "\n",
       "                                                   Url  Similarity  \n",
       "0    https://www.goodreads.com/book/show/33655366-t...    0.495827  \n",
       "1    https://www.goodreads.com/book/show/8705483-de...    0.392048  \n",
       "2    https://www.goodreads.com/book/show/215540.The...    0.353052  \n",
       "3    https://www.goodreads.com/book/show/2767052-th...    0.318387  \n",
       "4    https://www.goodreads.com/book/show/16070018-t...    0.247382  \n",
       "..                                                 ...         ...  \n",
       "108  https://www.goodreads.com/book/show/5369.The_A...    0.024363  \n",
       "109  https://www.goodreads.com/book/show/29082755-h...    0.024275  \n",
       "110  https://www.goodreads.com/book/show/39943621-f...    0.022846  \n",
       "111  https://www.goodreads.com/book/show/26005898-d...    0.018306  \n",
       "112  https://www.goodreads.com/book/show/17379067-t...    0.011589  \n",
       "\n",
       "[113 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_se.execute_query('survival games', 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
