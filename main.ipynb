{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:29:25.081321Z",
     "iopub.status.busy": "2020-11-25T16:29:25.080763Z",
     "iopub.status.idle": "2020-11-25T16:29:25.835658Z",
     "shell.execute_reply": "2020-11-25T16:29:25.835151Z",
     "shell.execute_reply.started": "2020-11-25T16:29:25.081184Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import string\n",
    "import data_collector\n",
    "import parser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of the books\n",
    "We already have the list of books in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both dirs, bests and links parameters to create the correct directories and download the txt containing all the html links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.588151Z",
     "iopub.status.busy": "2020-11-22T22:28:10.587988Z",
     "iopub.status.idle": "2020-11-22T22:28:10.591041Z",
     "shell.execute_reply": "2020-11-22T22:28:10.590475Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.588099Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(dirs=False, bests=False, links=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Crawl books\n",
    "We already have all the htmls in the pc, so we won't do it again.\n",
    "\n",
    "Set to `True` both the books and fails parameters to download all the html pages and remove the ones with broken pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.593990Z",
     "iopub.status.busy": "2020-11-22T22:28:10.593855Z",
     "iopub.status.idle": "2020-11-22T22:28:10.634453Z",
     "shell.execute_reply": "2020-11-22T22:28:10.633377Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.593972Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collector.download_books(books=False, fails=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Parse downloaded pages\n",
    "Set to `True` the create parameter to parse the downloaded html pages and create the tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.635794Z",
     "iopub.status.busy": "2020-11-22T22:28:10.635569Z",
     "iopub.status.idle": "2020-11-22T22:28:10.648884Z",
     "shell.execute_reply": "2020-11-22T22:28:10.648186Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.635759Z"
    }
   },
   "outputs": [],
   "source": [
    "parser.create_tsv(create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:59:22.631022Z",
     "iopub.status.busy": "2020-11-24T18:59:22.630731Z",
     "iopub.status.idle": "2020-11-24T18:59:22.982737Z",
     "shell.execute_reply": "2020-11-24T18:59:22.982126Z",
     "shell.execute_reply.started": "2020-11-24T18:59:22.630987Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('parsed_books.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.944542Z",
     "iopub.status.busy": "2020-11-22T22:28:10.944358Z",
     "iopub.status.idle": "2020-11-22T22:28:10.954676Z",
     "shell.execute_reply": "2020-11-22T22:28:10.954179Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.944519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29959, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T22:28:10.955475Z",
     "iopub.status.busy": "2020-11-22T22:28:10.955348Z",
     "iopub.status.idle": "2020-11-22T22:28:10.976507Z",
     "shell.execute_reply": "2020-11-22T22:28:10.975901Z",
     "shell.execute_reply.started": "2020-11-22T22:28:10.955459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>Could you survive on your own in the wild, wit...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>September 14th 2008</td>\n",
       "      <td>Katniss Everdeen Peeta Mellark Cato (Hunger Ga...</td>\n",
       "      <td>District 12, Panem Capitol, Panem Panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>September 2004</td>\n",
       "      <td>Sirius Black Draco Malfoy Ron Weasley Petunia ...</td>\n",
       "      <td>Hogwarts School of Witchcraft and Wizardry Lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>May 23rd 2006</td>\n",
       "      <td>Scout Finch Atticus Finch Jem Finch Arthur Rad...</td>\n",
       "      <td>Maycomb, Alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>October 10th 2000</td>\n",
       "      <td>Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...</td>\n",
       "      <td>United Kingdom Derbyshire, England England Her...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>September 6th 2006</td>\n",
       "      <td>Edward Cullen Jacob Black Laurent Renee Bella ...</td>\n",
       "      <td>Forks, Washington Phoenix, Arizona Washington ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  Suzanne Collins         4.33    6408798.0     172554.0   \n",
       "1     J.K. Rowling         4.50    2525157.0      42734.0   \n",
       "2       Harper Lee         4.28    4527405.0      91802.0   \n",
       "3      Jane Austen         4.26    3017830.0      67811.0   \n",
       "4  Stephenie Meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  Could you survive on your own in the wild, wit...          374.0   \n",
       "1  There is a door at the end of a silent corrido...          870.0   \n",
       "2  The unforgettable novel of a childhood in a sl...          324.0   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...          279.0   \n",
       "4  About three things I was absolutely positive.F...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  September 14th 2008  Katniss Everdeen Peeta Mellark Cato (Hunger Ga...   \n",
       "1       September 2004  Sirius Black Draco Malfoy Ron Weasley Petunia ...   \n",
       "2        May 23rd 2006  Scout Finch Atticus Finch Jem Finch Arthur Rad...   \n",
       "3    October 10th 2000  Mr. Bennet Mrs. Bennet Jane Bennet Elizabeth B...   \n",
       "4   September 6th 2006  Edward Cullen Jacob Black Laurent Renee Bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0            District 12, Panem Capitol, Panem Panem   \n",
       "1  Hogwarts School of Witchcraft and Wizardry Lon...   \n",
       "2                                   Maycomb, Alabama   \n",
       "3  United Kingdom Derbyshire, England England Her...   \n",
       "4  Forks, Washington Phoenix, Arizona Washington ...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset cleaning [preliminary steps]\n",
    "Before actually jumping into the work itself, we want our dataframe to be clean, meaning that there are some preliminary steps we need to perform on it. First of all, missing data is something we should pay attention to. Lot's of rows are going to have missing data somewhere, and dealing with missing data it's not that nice. Notice that this will include different strategies for each of the column we will be considering (more details below). Then there is the problem with punctuation, stopwords, stems and so on so forth, so basic text data preprocessing. Let's make a brief recap:\n",
    "\n",
    "1. **Missing data**\n",
    "    - `bookTitle`: if a book is missing the title, then we can safely just remove the instance. In fact, books that are missing the title are actually missing all the informations, meaning that there is a problem with the GoodReads specific link. Also, even if a book was missing just the title, we wouldn't have a way to refer to it, thus it wouldn't be really useful considering we're building a search engine.\n",
    "    - `bookSeries`, `Authors`, `Plot`, `PublishingDate`, `Characters`, `Setting`: if a book is missing one of the above mentioned columns, we can still include the book in the data, since the search engine could for example work with just the title. Obviously, we cannot just leave the values missing, since it would be really hard to perform any operation on that. These are all text columns, therefore the best way to address the missing values prolem is to replace NaNs with empty strings.\n",
    "    - `ratingValue`, `NumberofPages`: TODO?\n",
    "2. **Text data preprocessing**\n",
    "    - Punctuation removal: this is the first step we want to perform, since it is going to make the next steps much easier (e.g., language detection will be easier if there aren't plots composed just by punctuation symbols).\n",
    "    - Language detection: before doing anything else, we want to remove the books that present the books for which the plot isn't in english.\n",
    "    - Stopwords removal (of the `Plot` column only)\n",
    "    - Stemming (of the `Plot` column only)\n",
    "    - Lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title\n",
    "There are 774 books that are completely empty, and these corresponds to the ones that are missing the `bookTitle` column. If you give a look at the url, you can see that these are not given by our python script to download and parse the books, but actually from the fact that the link is broken. Also, you can see that all the books that are missing the `bookTitle` are also missing all the remaining data.\n",
    "\n",
    "This means that we can safely just remove all the rows that are missing the `bookTitle` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:59:29.728367Z",
     "iopub.status.busy": "2020-11-24T18:59:29.728119Z",
     "iopub.status.idle": "2020-11-24T18:59:29.747333Z",
     "shell.execute_reply": "2020-11-24T18:59:29.746947Z",
     "shell.execute_reply.started": "2020-11-24T18:59:29.728337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 774 instances that are missing the `bookTitle` column.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40937505\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528535\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/30528544\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/40941582\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.goodreads.com/book/show/5295735\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bookTitle bookSeries bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "311        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "370        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "379        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "789        NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "1141       NaN        NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Plot  numberOfPages PublishingDate Characters Setting  \\\n",
       "311   NaN            NaN            NaN        NaN     NaN   \n",
       "370   NaN            NaN            NaN        NaN     NaN   \n",
       "379   NaN            NaN            NaN        NaN     NaN   \n",
       "789   NaN            NaN            NaN        NaN     NaN   \n",
       "1141  NaN            NaN            NaN        NaN     NaN   \n",
       "\n",
       "                                                   Url  \n",
       "311   https://www.goodreads.com/book/show/40937505\\r\\n  \n",
       "370   https://www.goodreads.com/book/show/30528535\\r\\n  \n",
       "379   https://www.goodreads.com/book/show/30528544\\r\\n  \n",
       "789   https://www.goodreads.com/book/show/40941582\\r\\n  \n",
       "1141   https://www.goodreads.com/book/show/5295735\\r\\n  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing = df[(df['bookTitle'].isna())].shape[0]\n",
    "print('There are {} instances that are missing the `bookTitle` column.'.format(n_missing))\n",
    "print()\n",
    "df[(df['bookTitle'].isna())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:59:34.786958Z",
     "iopub.status.busy": "2020-11-24T18:59:34.786659Z",
     "iopub.status.idle": "2020-11-24T18:59:34.800669Z",
     "shell.execute_reply": "2020-11-24T18:59:34.799797Z",
     "shell.execute_reply.started": "2020-11-24T18:59:34.786923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove empty books\n",
    "df = df[(df['bookTitle'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:05:49.168608Z",
     "iopub.status.busy": "2020-11-24T21:05:49.167578Z",
     "iopub.status.idle": "2020-11-24T21:05:49.213514Z",
     "shell.execute_reply": "2020-11-24T21:05:49.212849Z",
     "shell.execute_reply.started": "2020-11-24T21:05:49.168469Z"
    }
   },
   "outputs": [],
   "source": [
    "str_columns = ['bookSeries', 'bookAuthors', 'Plot', 'PublishingDate', 'Characters', 'Setting']\n",
    "\n",
    "for col in str_columns:\n",
    "    df[col] = df[col].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "\n",
    "There are several ways to remove punctuations, including the use of exernal libraries (like nltk). But actually the fastest way to perform punctuation removal is the use of the internal methong translate, which is programmed in C and therefore it's much faster than the other options (give a look to this [link](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string) for a nice performance analysis of the various options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:05:40.817568Z",
     "iopub.status.busy": "2020-11-24T21:05:40.816922Z",
     "iopub.status.idle": "2020-11-24T21:05:40.827712Z",
     "shell.execute_reply": "2020-11-24T21:05:40.825597Z",
     "shell.execute_reply.started": "2020-11-24T21:05:40.817490Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation + '’—'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:05:52.251339Z",
     "iopub.status.busy": "2020-11-24T21:05:52.250671Z",
     "iopub.status.idle": "2020-11-24T21:05:52.963595Z",
     "shell.execute_reply": "2020-11-24T21:05:52.962070Z",
     "shell.execute_reply.started": "2020-11-24T21:05:52.251260Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T13:11:07.055797Z",
     "iopub.status.busy": "2020-11-22T13:11:07.055640Z",
     "iopub.status.idle": "2020-11-22T13:11:07.074512Z",
     "shell.execute_reply": "2020-11-22T13:11:07.073991Z",
     "shell.execute_reply.started": "2020-11-22T13:11:07.055779Z"
    }
   },
   "source": [
    "#### Language detection\n",
    "There are four possibilities `Plot` column of a given book:\n",
    "1. It is written in english\n",
    "2. It is written in another language\n",
    "3. It is empty\n",
    "4. It contains symbols, numbers, and so on\n",
    "\n",
    "We want to keep only the ones written in english or empty, so we are just going to discard the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:00:09.182106Z",
     "iopub.status.busy": "2020-11-24T19:00:09.181738Z",
     "iopub.status.idle": "2020-11-24T19:00:09.187161Z",
     "shell.execute_reply": "2020-11-24T19:00:09.186135Z",
     "shell.execute_reply.started": "2020-11-24T19:00:09.182062Z"
    }
   },
   "outputs": [],
   "source": [
    "def language(s):\n",
    "    if s == '':\n",
    "        return 'empty'\n",
    "    try:\n",
    "        return detect(s)\n",
    "    except:\n",
    "        return 'symbols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:00:09.515159Z",
     "iopub.status.busy": "2020-11-24T19:00:09.514854Z",
     "iopub.status.idle": "2020-11-24T19:02:18.398908Z",
     "shell.execute_reply": "2020-11-24T19:02:18.398394Z",
     "shell.execute_reply.started": "2020-11-24T19:00:09.515124Z"
    }
   },
   "outputs": [],
   "source": [
    "df['plot_lang'] = df['Plot'].apply(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:02:26.272023Z",
     "iopub.status.busy": "2020-11-24T19:02:26.271400Z",
     "iopub.status.idle": "2020-11-24T19:02:26.301381Z",
     "shell.execute_reply": "2020-11-24T19:02:26.300781Z",
     "shell.execute_reply.started": "2020-11-24T19:02:26.271946Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['plot_lang'] == 'en'].drop(columns=['plot_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:02:29.249924Z",
     "iopub.status.busy": "2020-11-24T19:02:29.249576Z",
     "iopub.status.idle": "2020-11-24T19:02:29.254789Z",
     "shell.execute_reply": "2020-11-24T19:02:29.254042Z",
     "shell.execute_reply.started": "2020-11-24T19:02:29.249882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26122, 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords removal\n",
    "We are not going to perform stopwords removal on all the columns, since we could remove important things (e.g., we don't want to remove anything from the names of the characters). The only column on which stopwords removal is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:04:12.722123Z",
     "iopub.status.busy": "2020-11-24T19:04:12.721653Z",
     "iopub.status.idle": "2020-11-24T19:04:12.729733Z",
     "shell.execute_reply": "2020-11-24T19:04:12.728454Z",
     "shell.execute_reply.started": "2020-11-24T19:04:12.722065Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(s):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:04:13.018392Z",
     "iopub.status.busy": "2020-11-24T19:04:13.018182Z",
     "iopub.status.idle": "2020-11-24T19:04:31.304786Z",
     "shell.execute_reply": "2020-11-24T19:04:31.304166Z",
     "shell.execute_reply.started": "2020-11-24T19:04:13.018366Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "As for the stopwords removal, the only column on which stemming is necessary is `Plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T13:15:46.916255Z",
     "iopub.status.busy": "2020-11-25T13:15:46.916100Z",
     "iopub.status.idle": "2020-11-25T13:15:46.919069Z",
     "shell.execute_reply": "2020-11-25T13:15:46.918640Z",
     "shell.execute_reply.started": "2020-11-25T13:15:46.916238Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemming(s):\n",
    "    ps = PorterStemmer()\n",
    "    tokens = word_tokenize(s)\n",
    "    return ' '.join([ps.stem(w) for w in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:04:57.541087Z",
     "iopub.status.busy": "2020-11-24T19:04:57.540793Z",
     "iopub.status.idle": "2020-11-24T19:06:25.732869Z",
     "shell.execute_reply": "2020-11-24T19:06:25.732315Z",
     "shell.execute_reply.started": "2020-11-24T19:04:57.541057Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Plot'] = df['Plot'].apply(stemming)\n",
    "df['Plot'] = df['Plot'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:16:37.617866Z",
     "iopub.status.busy": "2020-11-22T15:16:37.617156Z",
     "iopub.status.idle": "2020-11-22T15:17:23.722941Z",
     "shell.execute_reply": "2020-11-22T15:17:23.722477Z",
     "shell.execute_reply.started": "2020-11-22T15:16:37.617782Z"
    }
   },
   "source": [
    "#### Lowercase\n",
    "On the other hand, we want all the string columns to be lowercase, so that our search engine won't have problems with upper/lower case differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:06:25.733861Z",
     "iopub.status.busy": "2020-11-24T19:06:25.733720Z",
     "iopub.status.idle": "2020-11-24T19:06:25.823754Z",
     "shell.execute_reply": "2020-11-24T19:06:25.823225Z",
     "shell.execute_reply.started": "2020-11-24T19:06:25.733843Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in str_columns:\n",
    "    df[col] = df[col].apply(lambda w: w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:06:25.824739Z",
     "iopub.status.busy": "2020-11-24T19:06:25.824606Z",
     "iopub.status.idle": "2020-11-24T19:06:25.838242Z",
     "shell.execute_reply": "2020-11-24T19:06:25.837617Z",
     "shell.execute_reply.started": "2020-11-24T19:06:25.824722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>bookSeries</th>\n",
       "      <th>bookAuthors</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>ratingCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>Plot</th>\n",
       "      <th>numberOfPages</th>\n",
       "      <th>PublishingDate</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Setting</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>the hunger games 1</td>\n",
       "      <td>suzanne collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6408798.0</td>\n",
       "      <td>172554.0</td>\n",
       "      <td>could surviv wild everi one make sure dont liv...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>september 14th 2008</td>\n",
       "      <td>katniss everdeen peeta mellark cato hunger gam...</td>\n",
       "      <td>district 12 panem capitol panem panem</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>harry potter 5</td>\n",
       "      <td>jk rowling</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2525157.0</td>\n",
       "      <td>42734.0</td>\n",
       "      <td>there door end silent corridor and haunt harri...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>september 2004</td>\n",
       "      <td>sirius black draco malfoy ron weasley petunia ...</td>\n",
       "      <td>hogwarts school of witchcraft and wizardry lon...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>to kill a mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4527405.0</td>\n",
       "      <td>91802.0</td>\n",
       "      <td>the unforgett novel childhood sleepi southern ...</td>\n",
       "      <td>324.0</td>\n",
       "      <td>may 23rd 2006</td>\n",
       "      <td>scout finch atticus finch jem finch arthur rad...</td>\n",
       "      <td>maycomb alabama</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td></td>\n",
       "      <td>jane austen</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3017830.0</td>\n",
       "      <td>67811.0</td>\n",
       "      <td>altern cover edit isbn 9780679783268sinc immed...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>october 10th 2000</td>\n",
       "      <td>mr bennet mrs bennet jane bennet elizabeth ben...</td>\n",
       "      <td>united kingdom derbyshire england england hert...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>the twilight saga 1</td>\n",
       "      <td>stephenie meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4989910.0</td>\n",
       "      <td>104912.0</td>\n",
       "      <td>about three thing i absolut positivefirst edwa...</td>\n",
       "      <td>501.0</td>\n",
       "      <td>september 6th 2006</td>\n",
       "      <td>edward cullen jacob black laurent renee bella ...</td>\n",
       "      <td>forks washington phoenix arizona washington state</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bookTitle             bookSeries  \\\n",
       "0                           The Hunger Games     the hunger games 1   \n",
       "1  Harry Potter and the Order of the Phoenix         harry potter 5   \n",
       "2                      To Kill a Mockingbird  to kill a mockingbird   \n",
       "3                        Pride and Prejudice                          \n",
       "4                                   Twilight    the twilight saga 1   \n",
       "\n",
       "       bookAuthors  ratingValue  ratingCount  reviewCount  \\\n",
       "0  suzanne collins         4.33    6408798.0     172554.0   \n",
       "1       jk rowling         4.50    2525157.0      42734.0   \n",
       "2       harper lee         4.28    4527405.0      91802.0   \n",
       "3      jane austen         4.26    3017830.0      67811.0   \n",
       "4  stephenie meyer         3.60    4989910.0     104912.0   \n",
       "\n",
       "                                                Plot  numberOfPages  \\\n",
       "0  could surviv wild everi one make sure dont liv...          374.0   \n",
       "1  there door end silent corridor and haunt harri...          870.0   \n",
       "2  the unforgett novel childhood sleepi southern ...          324.0   \n",
       "3  altern cover edit isbn 9780679783268sinc immed...          279.0   \n",
       "4  about three thing i absolut positivefirst edwa...          501.0   \n",
       "\n",
       "        PublishingDate                                         Characters  \\\n",
       "0  september 14th 2008  katniss everdeen peeta mellark cato hunger gam...   \n",
       "1       september 2004  sirius black draco malfoy ron weasley petunia ...   \n",
       "2        may 23rd 2006  scout finch atticus finch jem finch arthur rad...   \n",
       "3    october 10th 2000  mr bennet mrs bennet jane bennet elizabeth ben...   \n",
       "4   september 6th 2006  edward cullen jacob black laurent renee bella ...   \n",
       "\n",
       "                                             Setting  \\\n",
       "0              district 12 panem capitol panem panem   \n",
       "1  hogwarts school of witchcraft and wizardry lon...   \n",
       "2                                    maycomb alabama   \n",
       "3  united kingdom derbyshire england england hert...   \n",
       "4  forks washington phoenix arizona washington state   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.goodreads.com/book/show/2767052-th...  \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...  \n",
       "2  https://www.goodreads.com/book/show/2657.To_Ki...  \n",
       "3  https://www.goodreads.com/book/show/1885.Pride...  \n",
       "4  https://www.goodreads.com/book/show/41865.Twil...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:06:25.839352Z",
     "iopub.status.busy": "2020-11-24T19:06:25.839146Z",
     "iopub.status.idle": "2020-11-24T19:06:25.853050Z",
     "shell.execute_reply": "2020-11-24T19:06:25.852416Z",
     "shell.execute_reply.started": "2020-11-24T19:06:25.839334Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:06:01.983271Z",
     "iopub.status.busy": "2020-11-24T21:06:01.982963Z",
     "iopub.status.idle": "2020-11-24T21:06:02.444110Z",
     "shell.execute_reply": "2020-11-24T21:06:02.442255Z",
     "shell.execute_reply.started": "2020-11-24T21:06:01.983236Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:29:31.856635Z",
     "iopub.status.busy": "2020-11-25T16:29:31.856447Z",
     "iopub.status.idle": "2020-11-25T16:29:32.063028Z",
     "shell.execute_reply": "2020-11-25T16:29:32.062516Z",
     "shell.execute_reply.started": "2020-11-25T16:29:31.856616Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:29:33.492216Z",
     "iopub.status.busy": "2020-11-25T16:29:33.492060Z",
     "iopub.status.idle": "2020-11-25T16:29:33.495493Z",
     "shell.execute_reply": "2020-11-25T16:29:33.494958Z",
     "shell.execute_reply.started": "2020-11-25T16:29:33.492197Z"
    }
   },
   "outputs": [],
   "source": [
    "# To save and load python dictionaries\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:29:34.683229Z",
     "iopub.status.busy": "2020-11-25T16:29:34.683075Z",
     "iopub.status.idle": "2020-11-25T16:29:34.686648Z",
     "shell.execute_reply": "2020-11-25T16:29:34.685988Z",
     "shell.execute_reply.started": "2020-11-25T16:29:34.683210Z"
    }
   },
   "outputs": [],
   "source": [
    "def term_index(documents):\n",
    "    words = set()\n",
    "    for s in documents:\n",
    "        try:\n",
    "            tokens = set(word_tokenize(s))\n",
    "            words.update(tokens)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    term_index = {}\n",
    "    for i, word in enumerate(words):\n",
    "        term_index[word] = i\n",
    "    return term_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:06:14.257916Z",
     "iopub.status.busy": "2020-11-24T21:06:14.257747Z",
     "iopub.status.idle": "2020-11-24T21:06:23.826791Z",
     "shell.execute_reply": "2020-11-24T21:06:23.826339Z",
     "shell.execute_reply.started": "2020-11-24T21:06:14.257897Z"
    }
   },
   "outputs": [],
   "source": [
    "term_indexes = term_index(df['Plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:06:23.827636Z",
     "iopub.status.busy": "2020-11-24T21:06:23.827505Z",
     "iopub.status.idle": "2020-11-24T21:06:23.859605Z",
     "shell.execute_reply": "2020-11-24T21:06:23.858846Z",
     "shell.execute_reply.started": "2020-11-24T21:06:23.827619Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(term_indexes, 'term_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:29:51.703694Z",
     "iopub.status.busy": "2020-11-25T16:29:51.703503Z",
     "iopub.status.idle": "2020-11-25T16:29:51.707324Z",
     "shell.execute_reply": "2020-11-25T16:29:51.706787Z",
     "shell.execute_reply.started": "2020-11-25T16:29:51.703671Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverted_index(documents, term_indexes):\n",
    "    inv_index = defaultdict(list)\n",
    "    for i, s in enumerate(documents):\n",
    "        try:\n",
    "            tokens = set(word_tokenize(s))\n",
    "            for token in tokens:\n",
    "                token_index = term_indexes[token]\n",
    "                inv_index[token_index].append(i)\n",
    "        except:\n",
    "            continue\n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:06:23.877814Z",
     "iopub.status.busy": "2020-11-24T21:06:23.877573Z",
     "iopub.status.idle": "2020-11-24T21:06:33.098496Z",
     "shell.execute_reply": "2020-11-24T21:06:33.097125Z",
     "shell.execute_reply.started": "2020-11-24T21:06:23.877785Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_indexes = inverted_index(df['Plot'], term_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T21:06:33.100930Z",
     "iopub.status.busy": "2020-11-24T21:06:33.100485Z",
     "iopub.status.idle": "2020-11-24T21:06:33.195304Z",
     "shell.execute_reply": "2020-11-24T21:06:33.194859Z",
     "shell.execute_reply.started": "2020-11-24T21:06:33.100873Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(inv_indexes, 'inverted_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:29:50.204472Z",
     "iopub.status.busy": "2020-11-25T16:29:50.203811Z",
     "iopub.status.idle": "2020-11-25T16:29:50.632418Z",
     "shell.execute_reply": "2020-11-25T16:29:50.631909Z",
     "shell.execute_reply.started": "2020-11-25T16:29:50.204388Z"
    }
   },
   "outputs": [],
   "source": [
    "term_indexes = load_obj('term_index')\n",
    "inv_indexes = load_obj('inverted_index')\n",
    "tfidf_indexes = load_obj('tfidf_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:16:57.209353Z",
     "iopub.status.busy": "2020-11-25T17:16:57.208992Z",
     "iopub.status.idle": "2020-11-25T17:16:57.217207Z",
     "shell.execute_reply": "2020-11-25T17:16:57.216610Z",
     "shell.execute_reply.started": "2020-11-25T17:16:57.209309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write it as a classs\n",
    "\n",
    "class SimpleSearchEngine:\n",
    "    def __init__(self, df, term_indexes, inv_indexes):\n",
    "        self.df = df\n",
    "        self.term_indexes = term_indexes\n",
    "        self.inv_indexes = inv_indexes\n",
    "        \n",
    "    def execute_query(self, query):\n",
    "        # Since we performed stemming on the plot column of the dataframe, we need to\n",
    "        # perform stemming also on the query. Otherwise, our results wouldn't be accurate\n",
    "        ps = PorterStemmer()\n",
    "        query_tokens = set([ps.stem(w) for w in word_tokenize(query)])\n",
    "\n",
    "        # Create term indexes for the query\n",
    "        # notice: if one of the query element doesn't appear in the term_indexes dictionary\n",
    "        # we can safely say that the **conjunctive** query has to return nothing\n",
    "        term_indexes_tokens = []\n",
    "        for token in query_tokens:\n",
    "            if token in self.term_indexes.keys():\n",
    "                term_indexes_tokens.append(self.term_indexes[token])\n",
    "            else:\n",
    "                print('No results')\n",
    "                return pd.DataFrame(columns=['bookTitle', 'Plot', 'Url'])\n",
    "\n",
    "        query_inv_indexes = {}\n",
    "        for token_index in term_indexes_tokens:\n",
    "            query_inv_indexes[token_index] = set(self.inv_indexes[token_index])\n",
    "\n",
    "        # Since it is a conjuntive query, we need to intersect the results of each query token\n",
    "        documents_id = sorted(set.intersection(*query_inv_indexes.values()))\n",
    "\n",
    "        return self.df[self.df['index'].isin(documents_id)][['bookTitle', 'Plot', 'Url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:33:37.751811Z",
     "iopub.status.busy": "2020-11-25T17:33:37.751655Z",
     "iopub.status.idle": "2020-11-25T17:33:37.754648Z",
     "shell.execute_reply": "2020-11-25T17:33:37.754003Z",
     "shell.execute_reply.started": "2020-11-25T17:33:37.751792Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_se = SimpleSearchEngine(df, term_indexes, inv_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:16:57.948026Z",
     "iopub.status.busy": "2020-11-25T17:16:57.947172Z",
     "iopub.status.idle": "2020-11-25T17:16:57.979037Z",
     "shell.execute_reply": "2020-11-25T17:16:57.978325Z",
     "shell.execute_reply.started": "2020-11-25T17:16:57.947912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>could surviv wild everi one make sure dont liv...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>spark are ignitingflam are spreadingand the ca...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6148028-ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Mockingjay</td>\n",
       "      <td>the final book groundbreak hunger game trilog ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/7260188-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Legend</td>\n",
       "      <td>what western unit state home republ nation per...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9275658-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>The Magus</td>\n",
       "      <td>thi dare literari thriller rich erot suspen on...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16286.The_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25063</th>\n",
       "      <td>The Manhattan Hunt Club</td>\n",
       "      <td>in manhattan hunt club john saul plumb depth m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6553.The_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25527</th>\n",
       "      <td>Love's Forbidden Flower</td>\n",
       "      <td>plea note thi new adult romanc novel involv tw...</td>\n",
       "      <td>https://www.goodreads.com/book/show/16189423-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25802</th>\n",
       "      <td>The Southpaw</td>\n",
       "      <td>the southpaw stori come age america way baseb ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/413736.The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25823</th>\n",
       "      <td>Devil's Own</td>\n",
       "      <td>after surviv slaveri aiden macalpin noth thoug...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8705483-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26060</th>\n",
       "      <td>Indian Hill</td>\n",
       "      <td>a michael talbot adventur thi first stori ordi...</td>\n",
       "      <td>https://www.goodreads.com/book/show/13305176-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bookTitle  \\\n",
       "0             The Hunger Games   \n",
       "221              Catching Fire   \n",
       "319                 Mockingjay   \n",
       "337                     Legend   \n",
       "652                  The Magus   \n",
       "...                        ...   \n",
       "25063  The Manhattan Hunt Club   \n",
       "25527  Love's Forbidden Flower   \n",
       "25802             The Southpaw   \n",
       "25823              Devil's Own   \n",
       "26060              Indian Hill   \n",
       "\n",
       "                                                    Plot  \\\n",
       "0      could surviv wild everi one make sure dont liv...   \n",
       "221    spark are ignitingflam are spreadingand the ca...   \n",
       "319    the final book groundbreak hunger game trilog ...   \n",
       "337    what western unit state home republ nation per...   \n",
       "652    thi dare literari thriller rich erot suspen on...   \n",
       "...                                                  ...   \n",
       "25063  in manhattan hunt club john saul plumb depth m...   \n",
       "25527  plea note thi new adult romanc novel involv tw...   \n",
       "25802  the southpaw stori come age america way baseb ...   \n",
       "25823  after surviv slaveri aiden macalpin noth thoug...   \n",
       "26060  a michael talbot adventur thi first stori ordi...   \n",
       "\n",
       "                                                     Url  \n",
       "0      https://www.goodreads.com/book/show/2767052-th...  \n",
       "221    https://www.goodreads.com/book/show/6148028-ca...  \n",
       "319    https://www.goodreads.com/book/show/7260188-mo...  \n",
       "337    https://www.goodreads.com/book/show/9275658-le...  \n",
       "652    https://www.goodreads.com/book/show/16286.The_...  \n",
       "...                                                  ...  \n",
       "25063  https://www.goodreads.com/book/show/6553.The_M...  \n",
       "25527  https://www.goodreads.com/book/show/16189423-l...  \n",
       "25802  https://www.goodreads.com/book/show/413736.The...  \n",
       "25823  https://www.goodreads.com/book/show/8705483-de...  \n",
       "26060  https://www.goodreads.com/book/show/13305176-i...  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_engine.execute_query('survival games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:43:46.899226Z",
     "iopub.status.busy": "2020-11-25T16:43:46.899056Z",
     "iopub.status.idle": "2020-11-25T16:43:46.903875Z",
     "shell.execute_reply": "2020-11-25T16:43:46.903302Z",
     "shell.execute_reply.started": "2020-11-25T16:43:46.899206Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_inv_indexes(documents, term_indexes, inv_indexes, corpus=df):\n",
    "    tfidf_indexes = defaultdict(dict)\n",
    "    for i, s in enumerate(documents):\n",
    "        try:\n",
    "            tokens = word_tokenize(s)\n",
    "            tokens_set = set(tokens)\n",
    "            n_tokens = len(tokens)\n",
    "            norm = 0\n",
    "            for token in tokens_set:\n",
    "                token_index = term_indexes[token]\n",
    "                tf = s.count(token) / n_tokens\n",
    "                idf = math.log10(len(corpus) / (len(inv_indexes[token_index])))\n",
    "                tf_idf = tf * idf\n",
    "                norm += tf_idf**2\n",
    "                tfidf_indexes[token_index][i] = tf * idf\n",
    "            \n",
    "            # Normalize each document tfidf\n",
    "            norm = np.sqrt(norm)\n",
    "            for token in tokens_set:\n",
    "                token_index = term_indexes[token]\n",
    "                tfidf_indexes[token_index][i] /= norm\n",
    "        except:\n",
    "            continue\n",
    "    return tfidf_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:41:13.192287Z",
     "iopub.status.busy": "2020-11-25T16:41:13.191262Z",
     "iopub.status.idle": "2020-11-25T16:41:27.793123Z",
     "shell.execute_reply": "2020-11-25T16:41:27.792648Z",
     "shell.execute_reply.started": "2020-11-25T16:41:13.192148Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_indexes = tfidf_inv_indexes(df['Plot'], term_indexes, inv_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T16:54:33.020242Z",
     "iopub.status.busy": "2020-11-25T16:54:33.019731Z",
     "iopub.status.idle": "2020-11-25T16:54:38.289757Z",
     "shell.execute_reply": "2020-11-25T16:54:38.289217Z",
     "shell.execute_reply.started": "2020-11-25T16:54:33.020184Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(tfidf_indexes, 'tfidf_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:34:51.536487Z",
     "iopub.status.busy": "2020-11-25T17:34:51.535852Z",
     "iopub.status.idle": "2020-11-25T17:34:51.545306Z",
     "shell.execute_reply": "2020-11-25T17:34:51.544833Z",
     "shell.execute_reply.started": "2020-11-25T17:34:51.536407Z"
    }
   },
   "outputs": [],
   "source": [
    "class TfidfSearchEngine:\n",
    "    def __init__(self, df, term_indexes, inv_indexes, tfidf_indexes, simple_se):\n",
    "        self.df = df\n",
    "        self.term_indexes = term_indexes\n",
    "        self.inv_indexes = inv_indexes\n",
    "        self.tfidf_indexes = tfidf_indexes\n",
    "        self.simple_se = simple_se\n",
    "        \n",
    "    def execute_query(self, query, k):\n",
    "        ps = PorterStemmer()\n",
    "        query_tokens = set([ps.stem(w) for w in word_tokenize(query)])\n",
    "\n",
    "        tokens_ids = []\n",
    "        for token in query_tokens:\n",
    "            try:\n",
    "                tokens_ids.append(self.term_indexes[token])\n",
    "            except:\n",
    "                return\n",
    "\n",
    "        conj_query = self.simple_se.execute_query(query)\n",
    "\n",
    "        conj_query_ids = conj_query.index\n",
    "\n",
    "\n",
    "        scores = np.array([])\n",
    "        for doc in conj_query_ids:\n",
    "            tfidf = 0\n",
    "            for token_id in tokens_ids:\n",
    "                tfidf += self.tfidf_indexes[token_id][doc]\n",
    "\n",
    "            scores = np.append(scores, tfidf)\n",
    "            \n",
    "        conj_query['Similarity'] = scores\n",
    "\n",
    "        # Use heaps to extract top k rows\n",
    "        conj_query_list = conj_query.values.tolist()\n",
    "        heapq.heapify(conj_query_list)\n",
    "        max_k = heapq.nlargest(k, conj_query_list, key = lambda t: t[3])\n",
    "\n",
    "        max_k_df = pd.DataFrame(data=max_k, columns=['bookTitle', 'Plot', 'Url', 'Similarity'])\n",
    "\n",
    "        return max_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:34:53.967655Z",
     "iopub.status.busy": "2020-11-25T17:34:53.967308Z",
     "iopub.status.idle": "2020-11-25T17:34:53.972053Z",
     "shell.execute_reply": "2020-11-25T17:34:53.971204Z",
     "shell.execute_reply.started": "2020-11-25T17:34:53.967611Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_se = TfidfSearchEngine(df, term_indexes, inv_indexes, tfidf_indexes, simple_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:35:03.141079Z",
     "iopub.status.busy": "2020-11-25T17:35:03.140616Z",
     "iopub.status.idle": "2020-11-25T17:35:03.155212Z",
     "shell.execute_reply": "2020-11-25T17:35:03.154583Z",
     "shell.execute_reply.started": "2020-11-25T17:35:03.141018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookTitle</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So You Want to Be a Wizard</td>\n",
       "      <td>nita callahan end rope bulli whove hound schoo...</td>\n",
       "      <td>https://www.goodreads.com/book/show/116563.So_...</td>\n",
       "      <td>0.487815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sourcery</td>\n",
       "      <td>when last seen singularli inept wizard rincewi...</td>\n",
       "      <td>https://www.goodreads.com/book/show/34499.Sour...</td>\n",
       "      <td>0.434745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Wizard of Dark Street</td>\n",
       "      <td>oona crate born wizard apprent anoth destini m...</td>\n",
       "      <td>https://www.goodreads.com/book/show/9668661-th...</td>\n",
       "      <td>0.388242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fairy Tail, Vol. 01</td>\n",
       "      <td>the wick side of wizardrycelesti wizard luci w...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2454986.Fa...</td>\n",
       "      <td>0.358335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wizards at War</td>\n",
       "      <td>nita kit return wizardli holiday look forward ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/116567.Wiz...</td>\n",
       "      <td>0.339397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mélusine</td>\n",
       "      <td>mélusin  citi secret lie pleasur pain magic co...</td>\n",
       "      <td>https://www.goodreads.com/book/show/492069.M_l...</td>\n",
       "      <td>0.331146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Young Wizards</td>\n",
       "      <td>book club collect so you want be wizard deep w...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2175442.Th...</td>\n",
       "      <td>0.314714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Proven Guilty</td>\n",
       "      <td>there love lost harri dresden wizard chicago p...</td>\n",
       "      <td>https://www.goodreads.com/book/show/91474.Prov...</td>\n",
       "      <td>0.312884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>harri potter midway train wizard come age harr...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6.Harry_Po...</td>\n",
       "      <td>0.301307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fantastic Beasts - The Crimes of Grindelwald: ...</td>\n",
       "      <td>at end fantast beast where find them power dar...</td>\n",
       "      <td>https://www.goodreads.com/book/show/39330961-f...</td>\n",
       "      <td>0.298715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           bookTitle  \\\n",
       "0                         So You Want to Be a Wizard   \n",
       "1                                           Sourcery   \n",
       "2                          The Wizard of Dark Street   \n",
       "3                                Fairy Tail, Vol. 01   \n",
       "4                                     Wizards at War   \n",
       "5                                           Mélusine   \n",
       "6                                  The Young Wizards   \n",
       "7                                      Proven Guilty   \n",
       "8                Harry Potter and the Goblet of Fire   \n",
       "9  Fantastic Beasts - The Crimes of Grindelwald: ...   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  nita callahan end rope bulli whove hound schoo...   \n",
       "1  when last seen singularli inept wizard rincewi...   \n",
       "2  oona crate born wizard apprent anoth destini m...   \n",
       "3  the wick side of wizardrycelesti wizard luci w...   \n",
       "4  nita kit return wizardli holiday look forward ...   \n",
       "5  mélusin  citi secret lie pleasur pain magic co...   \n",
       "6  book club collect so you want be wizard deep w...   \n",
       "7  there love lost harri dresden wizard chicago p...   \n",
       "8  harri potter midway train wizard come age harr...   \n",
       "9  at end fantast beast where find them power dar...   \n",
       "\n",
       "                                                 Url  Similarity  \n",
       "0  https://www.goodreads.com/book/show/116563.So_...    0.487815  \n",
       "1  https://www.goodreads.com/book/show/34499.Sour...    0.434745  \n",
       "2  https://www.goodreads.com/book/show/9668661-th...    0.388242  \n",
       "3  https://www.goodreads.com/book/show/2454986.Fa...    0.358335  \n",
       "4  https://www.goodreads.com/book/show/116567.Wiz...    0.339397  \n",
       "5  https://www.goodreads.com/book/show/492069.M_l...    0.331146  \n",
       "6  https://www.goodreads.com/book/show/2175442.Th...    0.314714  \n",
       "7  https://www.goodreads.com/book/show/91474.Prov...    0.312884  \n",
       "8  https://www.goodreads.com/book/show/6.Harry_Po...    0.301307  \n",
       "9  https://www.goodreads.com/book/show/39330961-f...    0.298715  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_se.execute_query('wizard', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
